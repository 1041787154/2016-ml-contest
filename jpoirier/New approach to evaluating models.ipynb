{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New approach to evaluating models  \n",
    "#### Joshua Poirier, [NEOS](http://www.neosgeo.com)  \n",
    "2016 SEG Machine Learning Contest  \n",
    "\n",
    "## 1 Introduction  \n",
    "\n",
    "The purpose of this notebook is to establish a new approach to evaluating models for this contest.  I propose a method which borrows from the **K-Folds** and **Leave-one-out** methods, wherein we build the model several times; each model is built by leaving out one well as the test set.  This method is designed to circumvent the circumstances of the contest wherein the prediction capability for the predefined blind well (**Newby**) is a loss function - leading to overfitting.  \n",
    "\n",
    "Time to load supporting libraries and the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualization packages\n",
    "library(repr)\n",
    "library(ggplot2)\n",
    "library(ggthemes)\n",
    "library(cowplot)\n",
    "\n",
    "# machine learning packages\n",
    "library(e1071)\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Facies</th><th scope=col>Formation</th><th scope=col>Well.Name</th><th scope=col>Depth</th><th scope=col>GR</th><th scope=col>ILD_log10</th><th scope=col>DeltaPHI</th><th scope=col>PHIND</th><th scope=col>PE</th><th scope=col>isMarine</th><th scope=col>RELPOS</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>FSiS     </td><td>A1 SH    </td><td>SHRIMPLIN</td><td>2793.0   </td><td>77.45    </td><td>0.664    </td><td> 9.9     </td><td>11.915   </td><td>4.6      </td><td>FALSE    </td><td>1.000    </td></tr>\n",
       "\t<tr><td>FSiS     </td><td>A1 SH    </td><td>SHRIMPLIN</td><td>2793.5   </td><td>78.26    </td><td>0.661    </td><td>14.2     </td><td>12.565   </td><td>4.1      </td><td>FALSE    </td><td>0.979    </td></tr>\n",
       "\t<tr><td>FSiS     </td><td>A1 SH    </td><td>SHRIMPLIN</td><td>2794.0   </td><td>79.05    </td><td>0.658    </td><td>14.8     </td><td>13.050   </td><td>3.6      </td><td>FALSE    </td><td>0.957    </td></tr>\n",
       "\t<tr><td>FSiS     </td><td>A1 SH    </td><td>SHRIMPLIN</td><td>2794.5   </td><td>86.10    </td><td>0.655    </td><td>13.9     </td><td>13.115   </td><td>3.5      </td><td>FALSE    </td><td>0.936    </td></tr>\n",
       "\t<tr><td>FSiS     </td><td>A1 SH    </td><td>SHRIMPLIN</td><td>2795.0   </td><td>74.58    </td><td>0.647    </td><td>13.5     </td><td>13.300   </td><td>3.4      </td><td>FALSE    </td><td>0.915    </td></tr>\n",
       "\t<tr><td>FSiS     </td><td>A1 SH    </td><td>SHRIMPLIN</td><td>2795.5   </td><td>73.97    </td><td>0.636    </td><td>14.0     </td><td>13.385   </td><td>3.6      </td><td>FALSE    </td><td>0.894    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       " Facies & Formation & Well.Name & Depth & GR & ILD\\_log10 & DeltaPHI & PHIND & PE & isMarine & RELPOS\\\\\n",
       "\\hline\n",
       "\t FSiS      & A1 SH     & SHRIMPLIN & 2793.0    & 77.45     & 0.664     &  9.9      & 11.915    & 4.6       & FALSE     & 1.000    \\\\\n",
       "\t FSiS      & A1 SH     & SHRIMPLIN & 2793.5    & 78.26     & 0.661     & 14.2      & 12.565    & 4.1       & FALSE     & 0.979    \\\\\n",
       "\t FSiS      & A1 SH     & SHRIMPLIN & 2794.0    & 79.05     & 0.658     & 14.8      & 13.050    & 3.6       & FALSE     & 0.957    \\\\\n",
       "\t FSiS      & A1 SH     & SHRIMPLIN & 2794.5    & 86.10     & 0.655     & 13.9      & 13.115    & 3.5       & FALSE     & 0.936    \\\\\n",
       "\t FSiS      & A1 SH     & SHRIMPLIN & 2795.0    & 74.58     & 0.647     & 13.5      & 13.300    & 3.4       & FALSE     & 0.915    \\\\\n",
       "\t FSiS      & A1 SH     & SHRIMPLIN & 2795.5    & 73.97     & 0.636     & 14.0      & 13.385    & 3.6       & FALSE     & 0.894    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  Facies Formation Well.Name Depth  GR    ILD_log10 DeltaPHI PHIND  PE \n",
       "1 FSiS   A1 SH     SHRIMPLIN 2793.0 77.45 0.664      9.9     11.915 4.6\n",
       "2 FSiS   A1 SH     SHRIMPLIN 2793.5 78.26 0.661     14.2     12.565 4.1\n",
       "3 FSiS   A1 SH     SHRIMPLIN 2794.0 79.05 0.658     14.8     13.050 3.6\n",
       "4 FSiS   A1 SH     SHRIMPLIN 2794.5 86.10 0.655     13.9     13.115 3.5\n",
       "5 FSiS   A1 SH     SHRIMPLIN 2795.0 74.58 0.647     13.5     13.300 3.4\n",
       "6 FSiS   A1 SH     SHRIMPLIN 2795.5 73.97 0.636     14.0     13.385 3.6\n",
       "  isMarine RELPOS\n",
       "1 FALSE    1.000 \n",
       "2 FALSE    0.979 \n",
       "3 FALSE    0.957 \n",
       "4 FALSE    0.936 \n",
       "5 FALSE    0.915 \n",
       "6 FALSE    0.894 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "fname <- \"../facies_vectors.csv\"\n",
    "data <- read.csv(fname, colClasses=c(rep(\"factor\",3), rep(\"numeric\",6), \"factor\", \"numeric\"))\n",
    "\n",
    "# convert NM_M channel into a binary channel \"isMarine\"\n",
    "data$NM_M <- data$NM_M == \"2\"\n",
    "names(data)[10] <- \"isMarine\"\n",
    "\n",
    "# make the Facies channel more descriptive\n",
    "levels(data$Facies) <- c(\"SS\", \"CSiS\", \"FSiS\", \"SiSh\", \"MS\", \"WS\", \"D\", \"PS\", \"BS\")\n",
    "\n",
    "# remove any incomplete records (we know from jpoirier001.ipynb PE channel is missing some values)\n",
    "data <- data[complete.cases(data),]\n",
    "\n",
    "# display first five rows of data set\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Tuning SVM parameters\n",
    "\n",
    "Noww let's apply our well-folds methodology wherein we loop through the wells and the current well iteration functions as the cross-validation data set while the remaining wells function as the training data.  Our tuning in *jpoirier001.ipynb* found that (using the randomly split data) the optimal SVM parameters were 10 for **Cost** and 1 for **Gamma**.  The tuning function tried **Cost** values of 0.01, 1, 5, 10, 20, 50, 100, 1000, 5000, and 10000 and **Gamma** values of 0.0001, 0.001, 0.01, 1, and 10.  Since we're going to apply this computationally intensive procedure multiple times, let's trim off a few of the end values.  \n",
    "\n",
    "Also note that we will not isolate the **Recruit F9** \"well\" because it is not a true well but a manually selected set of observations of the Bafflestone facies.  \n",
    "\n",
    "Let's start by building a function which tunes an SVM (Support Vector Machine) model.  We'll have it taken in two parameters:  **data** which is a data frame containing all observations from all wells, and **well** which is a string identifying which well should be used as the cross-validation set.  The function will start out by isolating the given well's data followed by tuning the SVM algorithm using a variety of **Cost** and **Gamma** parameters.  It then returns a list of each parameter pair and their associated performance.  Please note, this function may take several (if not tens of) minutes to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# WARNING: this function will take several minutes to complete\n",
    "tune_svm <- function(data, well) {\n",
    "    set.seed(3124)\n",
    "    \n",
    "    # isolate the well data\n",
    "    cvIndex <- data$Well.Name == well\n",
    "    cv <- data[cvIndex,]\n",
    "    \n",
    "    # apply tuning and return performances\n",
    "    tune.out <- tune(svm, Facies ~ ., data=cv, \n",
    "                 kernel=\"radial\",\n",
    "                 ranges=list(cost=c(16,18,20,22,24,26,28,30,32,34),\n",
    "                            gamma=c(.05,.1,.15,.2,.25,.3,.35,.4,.45,.5)))\n",
    "    \n",
    "    tune.out$performances\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement a new cross-validation method.  I'm calling it **Well-Folds**.  It combines the ideas behind **K-folds** and **leave-one-out**.  The idea is to **leave-one-out** where *one* is an entire well of observations.  It is similar to **K-folds** in that we are folding over the data set.  \n",
    "\n",
    "Why **Well-Folds**?  In this type of geoscience problem we are interested in developing a predictive model to classify facies for wells which do not have facies data recorded from core.  While classic machine learning problems are focused on predicting the outcome of a new observation, this geoscience application is interested in predicting the outcome (facies) for a set of observations from a new well.  The **Well-Folds** method best simulates this.  \n",
    "\n",
    "Let's now define the **Wells-fold** function.  It will take in two parameters.  The first parameter, **data**, is simply the data frame containing the observations for all wells.  The second parameter, **fxn**, is a function which is to be applied for each well in the **data** data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " well_folds_cv <- function(data, fxn) {\n",
    "    # list of wells\n",
    "    wells <- unique(data$Well.Name)\n",
    "    wells <- wells[-(which(wells == \"Recruit F9\"))]\n",
    "    \n",
    "    # initialize performances data frame\n",
    "    performances <- data.frame(cost=numeric(), gamma=numeric(), error=numeric(), dispersion=numeric(), well=factor())\n",
    "    \n",
    "    # tune algorithm for each well, record and return performance\n",
    "    for (well in wells) {\n",
    "        temp <- fxn(data, well)\n",
    "        temp$well <- well\n",
    "        performances <- rbind(performances, temp)\n",
    "    }\n",
    "     \n",
    "    # return data frame of parameters (incl. well) and their performance\n",
    "    performances\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our cross-validation (**well-folds**) and tuning functions (**tune_svm**) defined, let's apply them to our data set and preview the resulting parameters and performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>cost</th><th scope=col>gamma</th><th scope=col>error</th><th scope=col>dispersion</th><th scope=col>well</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>16        </td><td>0.05      </td><td>0.1379876 </td><td>0.04724347</td><td>SHRIMPLIN </td></tr>\n",
       "\t<tr><td>18        </td><td>0.05      </td><td>0.1401152 </td><td>0.04720575</td><td>SHRIMPLIN </td></tr>\n",
       "\t<tr><td>20        </td><td>0.05      </td><td>0.1337323 </td><td>0.05207576</td><td>SHRIMPLIN </td></tr>\n",
       "\t<tr><td>22        </td><td>0.05      </td><td>0.1358599 </td><td>0.05504759</td><td>SHRIMPLIN </td></tr>\n",
       "\t<tr><td>24        </td><td>0.05      </td><td>0.1337323 </td><td>0.05758017</td><td>SHRIMPLIN </td></tr>\n",
       "\t<tr><td>26        </td><td>0.05      </td><td>0.1337323 </td><td>0.05110074</td><td>SHRIMPLIN </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " cost & gamma & error & dispersion & well\\\\\n",
       "\\hline\n",
       "\t 16         & 0.05       & 0.1379876  & 0.04724347 & SHRIMPLIN \\\\\n",
       "\t 18         & 0.05       & 0.1401152  & 0.04720575 & SHRIMPLIN \\\\\n",
       "\t 20         & 0.05       & 0.1337323  & 0.05207576 & SHRIMPLIN \\\\\n",
       "\t 22         & 0.05       & 0.1358599  & 0.05504759 & SHRIMPLIN \\\\\n",
       "\t 24         & 0.05       & 0.1337323  & 0.05758017 & SHRIMPLIN \\\\\n",
       "\t 26         & 0.05       & 0.1337323  & 0.05110074 & SHRIMPLIN \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  cost gamma error     dispersion well     \n",
       "1 16   0.05  0.1379876 0.04724347 SHRIMPLIN\n",
       "2 18   0.05  0.1401152 0.04720575 SHRIMPLIN\n",
       "3 20   0.05  0.1337323 0.05207576 SHRIMPLIN\n",
       "4 22   0.05  0.1358599 0.05504759 SHRIMPLIN\n",
       "5 24   0.05  0.1337323 0.05758017 SHRIMPLIN\n",
       "6 26   0.05  0.1337323 0.05110074 SHRIMPLIN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tune the svm parameters\n",
    "# WARNING: this task can take several minutes (if not tens of minutes) to complete\n",
    "tuning <- well_folds_cv(data, tune_svm)\n",
    "head(tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the first few rows of the tuning results we can see that the model performance (measured by error and dispersion) vary depending on the **Cost** and **Gamma** values.  For each **Cost/Gamma** pair, we have an **error** for each well.  Now let's average those performance figures across the different wells for each **Cost/Gamma** pair and output those parameters which minimize the average error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>cost</th><th scope=col>gamma</th><th scope=col>mean_error</th><th scope=col>sd_error</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>32</th><td>22  </td><td>0.1 </td><td>0.16</td><td>0.06</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & cost & gamma & mean\\_error & sd\\_error\\\\\n",
       "\\hline\n",
       "\t32 & 22   & 0.1  & 0.16 & 0.06\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "   cost gamma mean_error sd_error\n",
       "32 22   0.1   0.16       0.06    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract the unique cost and gamma values used\n",
    "costs <- unique(tuning$cost)\n",
    "gammas <- unique(tuning$gamma)\n",
    "\n",
    "# initialize dataframe for statistics\n",
    "df <- data.frame(cost=numeric(), \n",
    "                 gamma=numeric(), \n",
    "                 mean_error=numeric(), \n",
    "                 sd_error=numeric())\n",
    "\n",
    "# loop through costs and gammas vectors, calculate performance stats for each pair\n",
    "for (cost in costs) {\n",
    "    for (gamma in gammas) {\n",
    "        # retrieve rows for current cost and gamma values\n",
    "        temp <- tuning[tuning$cost == cost & tuning$gamma == gamma,]\n",
    "        \n",
    "        # calculate mean and standard deviation of error\n",
    "        mean_error <- mean(temp$error)\n",
    "        sd_error <- sd(temp$error)\n",
    "        \n",
    "        # add the calculated stats to dataframe\n",
    "        df <- rbind(df, data.frame(cost=cost, \n",
    "                                   gamma=gamma, \n",
    "                                   mean_error=mean_error, \n",
    "                                   sd_error=sd_error))\n",
    "    }\n",
    "}\n",
    "\n",
    "# identify parameters with minimum average error\n",
    "dfmin <- df[which.min(df$mean_error),]\n",
    "round(dfmin,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting.  In *jpoirier001.ipynb* our random tuning (using a wider range of parameters) identified a **Cost** of 10 and **Gamma** of 1 to be optimal.  Here, we've found that a **Cost** of 22 and **Gamma** of 0.1 performs best.  To paint a more visual portrait of how the **Cost** and **Gamma** parameter selection influence model performance.  \n",
    "\n",
    "Let's graph the average and standard deviation of the **Error**.  Minimizing the average **Error** will give us the ideal parameters, while the **Standard Deviation** will give us an idea of the uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAAHgCAMAAABdO/S2AAAC4lBMVEUAAABHR0dQlb9boMpf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\n/weQXggxea1jYAAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=4)\n",
    "\n",
    "# mean error across wells\n",
    "g1 <- ggplot(df, aes(cost, gamma, fill=mean_error)) + theme_economist_white(gray_bg=T) +\n",
    "    geom_raster(alpha=.8) +\n",
    "    geom_point(data=dfmin, aes(cost, gamma)) +\n",
    "    geom_text(aes(x=dfmin$cost[1]+4, y=dfmin$gamma[1], \n",
    "                  label=paste(\"Minimum Error =\", round(dfmin$mean_error,2), \n",
    "                              \"\\n Cost=\", dfmin$cost[1], \"\\n Gamma=\", dfmin$gamma[1])), \n",
    "              size=2) +\n",
    "    labs(x=\"Cost\", y=\"Gamma\", title=\"Mean Error\") +\n",
    "    scale_fill_distiller(palette=\"Spectral\", name=\"\", direction=-1) +\n",
    "    theme(legend.position='none', \n",
    "          plot.title=element_text(size=8), \n",
    "          axis.text=element_text(size=8),\n",
    "          axis.title=element_text(size=8),\n",
    "          legend.text=element_text(size=8))\n",
    "\n",
    "# standard deviation of errors across wells\n",
    "g2 <- ggplot(df, aes(cost, gamma, fill=sd_error)) + theme_economist_white(gray_bg=T) +\n",
    "    geom_raster(alpha=.8) +\n",
    "    geom_point(data=dfmin, aes(cost, gamma)) +\n",
    "    geom_text(aes(x=dfmin$cost[1]+4, y=dfmin$gamma[1], \n",
    "                  label=paste(\"Minimum Error =\", round(dfmin$mean_error,2), \n",
    "                              \"\\n Cost=\", dfmin$cost[1], \"\\n Gamma=\", dfmin$gamma[1])), \n",
    "              size=2) +\n",
    "    labs(x=\"Cost\", y=\"Gamma\", title=\"Standard Deviation of Error\") +\n",
    "    scale_fill_distiller(palette=\"Spectral\", name=\"\", direction=-1) +\n",
    "    theme(legend.position='none', \n",
    "          plot.title=element_text(size=8), \n",
    "          axis.text=element_text(size=8),\n",
    "          axis.title=element_text(size=8),\n",
    "          legend.text=element_text(size=8))\n",
    "\n",
    "# bring two plots together and display\n",
    "g <- plot_grid(g1, g2, ncol=2)\n",
    "ggdraw() + \n",
    "    draw_plot(g, width=1, height=1, y=-.01) + \n",
    "    draw_plot_label(\"SVM Tuning\", size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raster plot of the standard deviations do not suggest some anomalous results.  The standard deviation of the minimum error is middling (yellow) - and that's ok.  Let's move forward using these parameters.  \n",
    "\n",
    "## Building and evaluating a classification model  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 3.2",
   "language": "R",
   "name": "ir32"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
