{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New approach to evaluating models  \n",
    "#### Joshua Poirier, [NEOS](http://www.neosgeo.com)  \n",
    "2016 SEG Machine Learning Contest  \n",
    "\n",
    "## 1 Introduction  \n",
    "\n",
    "The purpose of this notebook is to establish a new approach to evaluating models for this contest.  I propose a method which borrows from the **K-Folds** and **Leave-one-out** methods, wherein we build the model several times; each model is built by leaving out one well as the test set.\n",
    "\n",
    "Time to load supporting libraries and the data!  We'll also extract the **Shankle** well from the training data into a blind data set to be used for testing our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualization packages\n",
    "library(repr)\n",
    "library(ggplot2)\n",
    "library(ggthemes)\n",
    "library(cowplot)\n",
    "\n",
    "# machine learning packages\n",
    "library(e1071)\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Facies</th><th scope=col>Formation</th><th scope=col>Well.Name</th><th scope=col>Depth</th><th scope=col>GR</th><th scope=col>ILD_log10</th><th scope=col>DeltaPHI</th><th scope=col>PHIND</th><th scope=col>PE</th><th scope=col>isMarine</th><th scope=col>RELPOS</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>FSiS     </td><td>A1 SH    </td><td>SHRIMPLIN</td><td>2793.0   </td><td>77.45    </td><td>0.664    </td><td> 9.9     </td><td>11.915   </td><td>4.6      </td><td>FALSE    </td><td>1.000    </td></tr>\n",
       "\t<tr><td>FSiS     </td><td>A1 SH    </td><td>SHRIMPLIN</td><td>2793.5   </td><td>78.26    </td><td>0.661    </td><td>14.2     </td><td>12.565   </td><td>4.1      </td><td>FALSE    </td><td>0.979    </td></tr>\n",
       "\t<tr><td>FSiS     </td><td>A1 SH    </td><td>SHRIMPLIN</td><td>2794.0   </td><td>79.05    </td><td>0.658    </td><td>14.8     </td><td>13.050   </td><td>3.6      </td><td>FALSE    </td><td>0.957    </td></tr>\n",
       "\t<tr><td>FSiS     </td><td>A1 SH    </td><td>SHRIMPLIN</td><td>2794.5   </td><td>86.10    </td><td>0.655    </td><td>13.9     </td><td>13.115   </td><td>3.5      </td><td>FALSE    </td><td>0.936    </td></tr>\n",
       "\t<tr><td>FSiS     </td><td>A1 SH    </td><td>SHRIMPLIN</td><td>2795.0   </td><td>74.58    </td><td>0.647    </td><td>13.5     </td><td>13.300   </td><td>3.4      </td><td>FALSE    </td><td>0.915    </td></tr>\n",
       "\t<tr><td>FSiS     </td><td>A1 SH    </td><td>SHRIMPLIN</td><td>2795.5   </td><td>73.97    </td><td>0.636    </td><td>14.0     </td><td>13.385   </td><td>3.6      </td><td>FALSE    </td><td>0.894    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       " Facies & Formation & Well.Name & Depth & GR & ILD\\_log10 & DeltaPHI & PHIND & PE & isMarine & RELPOS\\\\\n",
       "\\hline\n",
       "\t FSiS      & A1 SH     & SHRIMPLIN & 2793.0    & 77.45     & 0.664     &  9.9      & 11.915    & 4.6       & FALSE     & 1.000    \\\\\n",
       "\t FSiS      & A1 SH     & SHRIMPLIN & 2793.5    & 78.26     & 0.661     & 14.2      & 12.565    & 4.1       & FALSE     & 0.979    \\\\\n",
       "\t FSiS      & A1 SH     & SHRIMPLIN & 2794.0    & 79.05     & 0.658     & 14.8      & 13.050    & 3.6       & FALSE     & 0.957    \\\\\n",
       "\t FSiS      & A1 SH     & SHRIMPLIN & 2794.5    & 86.10     & 0.655     & 13.9      & 13.115    & 3.5       & FALSE     & 0.936    \\\\\n",
       "\t FSiS      & A1 SH     & SHRIMPLIN & 2795.0    & 74.58     & 0.647     & 13.5      & 13.300    & 3.4       & FALSE     & 0.915    \\\\\n",
       "\t FSiS      & A1 SH     & SHRIMPLIN & 2795.5    & 73.97     & 0.636     & 14.0      & 13.385    & 3.6       & FALSE     & 0.894    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  Facies Formation Well.Name Depth  GR    ILD_log10 DeltaPHI PHIND  PE \n",
       "1 FSiS   A1 SH     SHRIMPLIN 2793.0 77.45 0.664      9.9     11.915 4.6\n",
       "2 FSiS   A1 SH     SHRIMPLIN 2793.5 78.26 0.661     14.2     12.565 4.1\n",
       "3 FSiS   A1 SH     SHRIMPLIN 2794.0 79.05 0.658     14.8     13.050 3.6\n",
       "4 FSiS   A1 SH     SHRIMPLIN 2794.5 86.10 0.655     13.9     13.115 3.5\n",
       "5 FSiS   A1 SH     SHRIMPLIN 2795.0 74.58 0.647     13.5     13.300 3.4\n",
       "6 FSiS   A1 SH     SHRIMPLIN 2795.5 73.97 0.636     14.0     13.385 3.6\n",
       "  isMarine RELPOS\n",
       "1 FALSE    1.000 \n",
       "2 FALSE    0.979 \n",
       "3 FALSE    0.957 \n",
       "4 FALSE    0.936 \n",
       "5 FALSE    0.915 \n",
       "6 FALSE    0.894 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "fname <- \"../facies_vectors.csv\"\n",
    "data <- read.csv(fname, colClasses=c(rep(\"factor\",3), rep(\"numeric\",6), \"factor\", \"numeric\"))\n",
    "\n",
    "# convert NM_M channel into a binary channel \"isMarine\"\n",
    "data$NM_M <- data$NM_M == \"2\"\n",
    "names(data)[10] <- \"isMarine\"\n",
    "\n",
    "# make the Facies channel more descriptive\n",
    "levels(data$Facies) <- c(\"SS\", \"CSiS\", \"FSiS\", \"SiSh\", \"MS\", \"WS\", \"D\", \"PS\", \"BS\")\n",
    "\n",
    "# remove any incomplete records (we know from jpoirier001.ipynb PE channel is missing some values)\n",
    "data <- data[complete.cases(data),]\n",
    "\n",
    "# split out SHANKLE well as test set into 'blind' data frame\n",
    "test_index <- data$Well.Name == \"SHANKLE\"\n",
    "blind <- data[test_index,]\n",
    "data <- data[!test_index,]\n",
    "\n",
    "# display first five rows of data set\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Model evaluation methodology  \n",
    "\n",
    "The contest is using the overall F1-score (applied to the blind well **Shankle**) to evaluate models.  The highest F1-score wins!  It thereby makes sense that we evaluate our models using the F1-score from tuning through training and testing.  Let's devise a function to take in the models predicted and true values and calculate it's Precision, Recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_metrics <- function(cm, ytrue) {\n",
    "    \n",
    "    # initialize vectors for precision, recall, and f1 metrics with zeros\n",
    "    prec <- rep(0,9)\n",
    "    recall <- rep(0,9)\n",
    "    f1 <- rep(0,9)\n",
    "\n",
    "    # loop through facies to compute precision, recall, and f1 for each facies\n",
    "    beta <- 1\n",
    "    for (i in 1:9) {\n",
    "        prec[i] <- cm[i,i] / sum(cm[i,])\n",
    "        recall[i] <- cm[i,i] / sum(cm[,i])\n",
    "        f1[i] <- (1 + beta^2) * prec[i] * recall[i] / ((beta^2 * prec[i]) + recall[i])\n",
    "    }\n",
    "    \n",
    "    prec[is.na(prec)] <- 0\n",
    "    recall[is.na(recall)] <- 0\n",
    "    f1[is.na(f1)] <- 0\n",
    "    \n",
    "    support <- as.matrix(table(ytrue))\n",
    "    tot_precision <- sum(prec * support) / sum(support)\n",
    "    tot_recall <- sum(recall * support) / sum(support)\n",
    "    tot_f1 <- sum(f1 * support) / sum(support)\n",
    "    \n",
    "    c(tot_precision, tot_recall, tot_f1)\n",
    "}\n",
    "\n",
    "eval_model <- function(ypred, ytrue) {\n",
    "    cm <- confusionMatrix(ypred, ytrue)\n",
    "    accuracy_metrics(as.matrix(cm[[\"table\"]]), ytrue)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Tuning SVM parameters\n",
    "\n",
    "Noww let's apply our well-folds methodology wherein we loop through the wells and the current well iteration functions as the cross-validation data set while the remaining wells function as the training data.  Our tuning in *jpoirier001.ipynb* found that (using the randomly split data) the optimal SVM parameters were 10 for **Cost** and 1 for **Gamma**.   \n",
    "\n",
    "Also note that we will not isolate the **Recruit F9** \"well\" because it is not a true well but a manually selected set of observations of the Bafflestone facies.  \n",
    "\n",
    "Let's start by building a function which tunes an SVM (Support Vector Machine) model.  We'll have it taken in two parameters:  **data** which is a data frame containing all observations from all wells, and **well** which is a string identifying which well should be used as the cross-validation set.  The function will start out by isolating the given well's data followed by tuning the SVM algorithm using a variety of **Cost** and **Gamma** parameters.  It then returns a list of each parameter pair and their associated performance.  Please note, this function may take several (if not tens of) minutes to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# WARNING: this function will take several minutes to complete\n",
    "tune_svm <- function(train, cv) {\n",
    "    \n",
    "    # tuning parameters\n",
    "    costs <- c(.01,5,10,15,20,25,30)\n",
    "    gammas <- c(.0001,.001,.01,.1,1,10)\n",
    "    \n",
    "    # initialize performance dataframe\n",
    "    performances <- data.frame(cost=numeric(), gamma=numeric(), \n",
    "                               precision=numeric(), recall=numeric(), f1=numeric())\n",
    "    \n",
    "    # loop through each cost and gamma pairing\n",
    "    for (c in costs) {\n",
    "        for (g in gammas) {\n",
    "            set.seed(3124)\n",
    "            \n",
    "            # build model and predict facies\n",
    "            fit <- svm(Facies ~ ., data=train, kernel='radial', cost=c, gamma=g)\n",
    "            pred <- predict(fit, newdata=cv)\n",
    "            \n",
    "            # evaluate model and store performance\n",
    "            metrics <- eval_model(pred, cv$Facies)\n",
    "            temp <- data.frame(cost=c, gamma=g, precision=metrics[1], recall=metrics[2], f1=metrics[3])\n",
    "            performances <- rbind(performances, temp)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # return data frame of parameters and performances\n",
    "    performances\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement a new cross-validation method.  I'm calling it **Well-Folds**.  It combines the ideas behind **K-folds** and **leave-one-out**.  The idea is to **leave-one-out** where *one* is an entire well of observations.  It is similar to **K-folds** in that we are folding over the data set.  \n",
    "\n",
    "Why **Well-Folds**?  In this type of geoscience problem we are interested in developing a predictive model to classify facies for wells which do not have facies data recorded from core.  While classic machine learning problems are focused on predicting the outcome of a new observation, this geoscience application is interested in predicting the outcome (facies) for a set of observations from a new well.  The **Well-Folds** method best simulates this.  \n",
    "\n",
    "Let's now define the **Wells-fold** function.  It will take in two parameters.  The first parameter, **data**, is simply the data frame containing the observations for all wells.  The second parameter, **fxn**, is a function which is to be applied for each well in the **data** data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " well_folds_cv <- function(data, fxn) {\n",
    "    # list of wells\n",
    "    wells <- unique(data$Well.Name)\n",
    "    wells <- wells[-(which(wells == \"Recruit F9\"))]\n",
    "    \n",
    "    # initialize performances data frame\n",
    "    performances <- data.frame(cost=numeric(), gamma=numeric(), \n",
    "                               precision=numeric(), recall=numeric(), f1=numeric(), \n",
    "                               well=factor())\n",
    "    \n",
    "    # tune algorithm for each well, record and return performance\n",
    "    for (well in wells) {\n",
    "        cvIndex <- data$Well.Name == well\n",
    "        temp <- fxn(data[!cvIndex, -c(2,3,4)], data[cvIndex, -c(2,3,4)])\n",
    "        temp$well <- well\n",
    "        performances <- rbind(performances, temp)\n",
    "    }\n",
    "     \n",
    "    # return data frame of parameters (incl. well) and their performance\n",
    "    performances\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our cross-validation (**well-folds**) and tuning functions (**tune_svm**) defined, let's apply them to our data set and preview the resulting parameters and performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>cost</th><th scope=col>gamma</th><th scope=col>precision</th><th scope=col>recall</th><th scope=col>f1</th><th scope=col>well</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.01      </td><td>1e-04     </td><td>0.06276567</td><td>0.2505308 </td><td>0.1003825 </td><td>SHRIMPLIN </td></tr>\n",
       "\t<tr><td>0.01      </td><td>1e-03     </td><td>0.06276567</td><td>0.2505308 </td><td>0.1003825 </td><td>SHRIMPLIN </td></tr>\n",
       "\t<tr><td>0.01      </td><td>1e-02     </td><td>0.06276567</td><td>0.2505308 </td><td>0.1003825 </td><td>SHRIMPLIN </td></tr>\n",
       "\t<tr><td>0.01      </td><td>1e-01     </td><td>0.15541413</td><td>0.3821656 </td><td>0.2201880 </td><td>SHRIMPLIN </td></tr>\n",
       "\t<tr><td>0.01      </td><td>1e+00     </td><td>0.06276567</td><td>0.2505308 </td><td>0.1003825 </td><td>SHRIMPLIN </td></tr>\n",
       "\t<tr><td>0.01      </td><td>1e+01     </td><td>0.06276567</td><td>0.2505308 </td><td>0.1003825 </td><td>SHRIMPLIN </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " cost & gamma & precision & recall & f1 & well\\\\\n",
       "\\hline\n",
       "\t 0.01       & 1e-04      & 0.06276567 & 0.2505308  & 0.1003825  & SHRIMPLIN \\\\\n",
       "\t 0.01       & 1e-03      & 0.06276567 & 0.2505308  & 0.1003825  & SHRIMPLIN \\\\\n",
       "\t 0.01       & 1e-02      & 0.06276567 & 0.2505308  & 0.1003825  & SHRIMPLIN \\\\\n",
       "\t 0.01       & 1e-01      & 0.15541413 & 0.3821656  & 0.2201880  & SHRIMPLIN \\\\\n",
       "\t 0.01       & 1e+00      & 0.06276567 & 0.2505308  & 0.1003825  & SHRIMPLIN \\\\\n",
       "\t 0.01       & 1e+01      & 0.06276567 & 0.2505308  & 0.1003825  & SHRIMPLIN \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  cost gamma precision  recall    f1        well     \n",
       "1 0.01 1e-04 0.06276567 0.2505308 0.1003825 SHRIMPLIN\n",
       "2 0.01 1e-03 0.06276567 0.2505308 0.1003825 SHRIMPLIN\n",
       "3 0.01 1e-02 0.06276567 0.2505308 0.1003825 SHRIMPLIN\n",
       "4 0.01 1e-01 0.15541413 0.3821656 0.2201880 SHRIMPLIN\n",
       "5 0.01 1e+00 0.06276567 0.2505308 0.1003825 SHRIMPLIN\n",
       "6 0.01 1e+01 0.06276567 0.2505308 0.1003825 SHRIMPLIN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tune the svm parameters\n",
    "# WARNING: this task can take several minutes (if not tens of minutes) to complete\n",
    "tuning <- well_folds_cv(data, tune_svm)\n",
    "head(tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the first few rows of the tuning results we can see that the model performance (measured by error and dispersion) vary depending on the **Cost** and **Gamma** values.  For each **Cost/Gamma** pair, we have a **precision**, **recall**, and **f1** for each well.  Now let's average those performance figures across the different wells for each **Cost/Gamma** pair and output those parameters which maximize the average F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>cost</th><th scope=col>gamma</th><th scope=col>mean_precision</th><th scope=col>mean_recall</th><th scope=col>mean_f1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>21</th><td>15  </td><td>0.01</td><td>0.55</td><td>0.51</td><td>0.49</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & cost & gamma & mean\\_precision & mean\\_recall & mean\\_f1\\\\\n",
       "\\hline\n",
       "\t21 & 15   & 0.01 & 0.55 & 0.51 & 0.49\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "   cost gamma mean_precision mean_recall mean_f1\n",
       "21 15   0.01  0.55           0.51        0.49   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract the unique cost and gamma values used\n",
    "costs <- unique(tuning$cost)\n",
    "gammas <- unique(tuning$gamma)\n",
    "\n",
    "# initialize dataframe for statistics\n",
    "df <- data.frame(cost=numeric(), \n",
    "                 gamma=numeric(), \n",
    "                 mean_precision=numeric(),\n",
    "                 mean_recall=numeric(),\n",
    "                 mean_f1=numeric())\n",
    "\n",
    "# loop through costs and gammas vectors, calculate performance stats for each pair\n",
    "for (cost in costs) {\n",
    "    for (gamma in gammas) {\n",
    "        # retrieve rows for current cost and gamma values\n",
    "        temp <- tuning[tuning$cost == cost & tuning$gamma == gamma,]\n",
    "        \n",
    "        # calculate mean and standard deviation of error\n",
    "        mean_precision <- mean(temp$precision)\n",
    "        mean_recall <- mean(temp$recall)\n",
    "        mean_f1 <- mean(temp$f1)\n",
    "        \n",
    "        # add the calculated stats to dataframe\n",
    "        df <- rbind(df, data.frame(cost=cost, \n",
    "                                   gamma=gamma, \n",
    "                                   mean_precision=mean_precision,\n",
    "                                   mean_recall=mean_recall,\n",
    "                                   mean_f1=mean_f1))\n",
    "    }\n",
    "}\n",
    "\n",
    "# identify parameters with minimum average error\n",
    "dfmax <- df[which.max(df$mean_f1),]\n",
    "round(dfmax,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting.  In *jpoirier001.ipynb* our tuning identified a **Cost** of 10 and **Gamma** of 1 to be optimal.  Here, we've found that a **Cost** of 15 and **Gamma** of 0.01 performs best.  To paint a more visual portrait of how the **Cost** and **Gamma** parameter selection influence model performance.  \n",
    "\n",
    "Let's graph the average **precision**, **recall**, and **F1-score** for each **Cost/Gamma** pair.  Maximizing the average **F1-score** will give us the ideal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAAFoCAMAAACv2GIDAAABg1BMVEUAAABHR0dQlb9boMpg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\nYQgYIGEIGCBhCBggYf4fApYBmFcn1ygAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=3)\n",
    "\n",
    "# mean precision across wells\n",
    "g1 <- ggplot(df, aes(cost, gamma, fill=mean_precision)) + theme_economist_white(gray_bg=T) +\n",
    "    geom_raster(alpha=.8) +\n",
    "    geom_point(data=dfmax, aes(cost, gamma)) +\n",
    "    geom_text(aes(x=dfmax$cost[1]-4, y=dfmax$gamma[1], \n",
    "                  label=paste(\"Maximum mean F1-Score =\", round(dfmax$mean_f1,2), \n",
    "                              \"\\n Cost=\", dfmax$cost[1], \"\\n Gamma=\", dfmax$gamma[1])), \n",
    "              size=2) +\n",
    "    scale_y_log10() +\n",
    "    labs(x=\"Cost\", y=\"Gamma\", title=\"Mean Precision\") +\n",
    "    scale_fill_distiller(palette=\"Spectral\", name=\"\", direction=-1) +\n",
    "    theme(legend.position='none', \n",
    "          plot.title=element_text(size=8), \n",
    "          axis.text=element_text(size=8),\n",
    "          axis.title=element_text(size=8),\n",
    "          legend.text=element_text(size=8))\n",
    "\n",
    "# mean recall across wells\n",
    "g2 <- ggplot(df, aes(cost, gamma, fill=mean_recall)) + theme_economist_white(gray_bg=T) +\n",
    "    geom_raster(alpha=.8) +\n",
    "    geom_point(data=dfmax, aes(cost, gamma)) +\n",
    "    geom_text(aes(x=dfmax$cost[1]-4, y=dfmax$gamma[1], \n",
    "                  label=paste(\"Maximum mean F1-Score =\", round(dfmax$mean_f1,2), \n",
    "                              \"\\n Cost=\", dfmax$cost[1], \"\\n Gamma=\", dfmax$gamma[1])), \n",
    "              size=2) +\n",
    "    scale_y_log10() +\n",
    "    labs(x=\"Cost\", y=\"Gamma\", title=\"Mean Recall\") +\n",
    "    scale_fill_distiller(palette=\"Spectral\", name=\"\", direction=-1) +\n",
    "    theme(legend.position='none', \n",
    "          plot.title=element_text(size=8), \n",
    "          axis.text=element_text(size=8),\n",
    "          axis.title=element_text(size=8),\n",
    "          legend.text=element_text(size=8))\n",
    "\n",
    "# mean f1-score across wells\n",
    "g3 <- ggplot(df, aes(cost, gamma, fill=mean_f1)) + theme_economist_white(gray_bg=T) +\n",
    "    geom_raster(alpha=.8) +\n",
    "    geom_point(data=dfmax, aes(cost, gamma)) +\n",
    "    geom_text(aes(x=dfmax$cost[1]-4, y=dfmax$gamma[1], \n",
    "                  label=paste(\"Maximum mean F1-Score =\", round(dfmax$mean_f1,2), \n",
    "                              \"\\n Cost=\", dfmax$cost[1], \"\\n Gamma=\", dfmax$gamma[1])), \n",
    "              size=2) +\n",
    "    scale_y_log10() +\n",
    "    labs(x=\"Cost\", y=\"Gamma\", title=\"Mean F1-Score\") +\n",
    "    scale_fill_distiller(palette=\"Spectral\", name=\"\", direction=-1) +\n",
    "    theme(legend.position='none', \n",
    "          plot.title=element_text(size=8), \n",
    "          axis.text=element_text(size=8),\n",
    "          axis.title=element_text(size=8),\n",
    "          legend.text=element_text(size=8))\n",
    "\n",
    "\n",
    "# bring two plots together and display\n",
    "g <- plot_grid(g1, g2, g3, ncol=3)\n",
    "ggdraw() + \n",
    "    draw_plot(g, width=1, height=1, y=-.01) + \n",
    "    draw_plot_label(\"SVM Tuning\", size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These raster plots show that our chosen cost and gamma of 15 and 0.01 respectively maximize the overall F1-score (0.49), and appear to be maxima for the overall precision and recall as well.  \n",
    "\n",
    "## 4 Assessing our training model  \n",
    "\n",
    "Let's now begin training our model using the optimized tuning parameters.  We'll use our **Well-folds** algorithm to average our metrics, gaining an idea of how the model is performing.  But first, we need to define our training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WARNING: this function will take several minutes to complete\n",
    "train_svm <- function(train, cv) {\n",
    "\n",
    "    set.seed(3124)\n",
    "    \n",
    "    # build model and predict facies\n",
    "    fit <- svm(Facies ~ ., data=train, kernel='radial', cost=15, gamma=.01)\n",
    "    pred <- predict(fit, newdata=cv)\n",
    "\n",
    "    # evaluate model and store performance\n",
    "    metrics <- eval_model(pred, cv$Facies)\n",
    "    data.frame(cost=15, gamma=.01, precision=metrics[1], recall=metrics[2], f1=metrics[3])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training function (above) takes in a training set and a cross-validation set.  The function builds an SVM model from the training set and applies it to the cross-validation set, returning metrics on the models performance.  Let's apply it to our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>cost</th><th scope=col>gamma</th><th scope=col>precision</th><th scope=col>recall</th><th scope=col>f1</th><th scope=col>well</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>15             </td><td>0.01           </td><td>0.66           </td><td>0.56           </td><td>0.52           </td><td>SHRIMPLIN      </td></tr>\n",
       "\t<tr><td>15             </td><td>0.01           </td><td>0.69           </td><td>0.58           </td><td>0.59           </td><td>LUKE G U       </td></tr>\n",
       "\t<tr><td>15             </td><td>0.01           </td><td>0.25           </td><td>0.32           </td><td>0.26           </td><td>CROSS H CATTLE </td></tr>\n",
       "\t<tr><td>15             </td><td>0.01           </td><td>0.58           </td><td>0.55           </td><td>0.54           </td><td>NOLAN          </td></tr>\n",
       "\t<tr><td>15             </td><td>0.01           </td><td>0.57           </td><td>0.52           </td><td>0.50           </td><td>NEWBY          </td></tr>\n",
       "\t<tr><td>15             </td><td>0.01           </td><td>0.56           </td><td>0.52           </td><td>0.50           </td><td>CHURCHMAN BIBLE</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " cost & gamma & precision & recall & f1 & well\\\\\n",
       "\\hline\n",
       "\t 15              & 0.01            & 0.66            & 0.56            & 0.52            & SHRIMPLIN      \\\\\n",
       "\t 15              & 0.01            & 0.69            & 0.58            & 0.59            & LUKE G U       \\\\\n",
       "\t 15              & 0.01            & 0.25            & 0.32            & 0.26            & CROSS H CATTLE \\\\\n",
       "\t 15              & 0.01            & 0.58            & 0.55            & 0.54            & NOLAN          \\\\\n",
       "\t 15              & 0.01            & 0.57            & 0.52            & 0.50            & NEWBY          \\\\\n",
       "\t 15              & 0.01            & 0.56            & 0.52            & 0.50            & CHURCHMAN BIBLE\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  cost gamma precision recall f1   well           \n",
       "1 15   0.01  0.66      0.56   0.52 SHRIMPLIN      \n",
       "2 15   0.01  0.69      0.58   0.59 LUKE G U       \n",
       "3 15   0.01  0.25      0.32   0.26 CROSS H CATTLE \n",
       "4 15   0.01  0.58      0.55   0.54 NOLAN          \n",
       "5 15   0.01  0.57      0.52   0.50 NEWBY          \n",
       "6 15   0.01  0.56      0.52   0.50 CHURCHMAN BIBLE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply well-folds to train model\n",
    "# WARNING: this task can a couple of minutes to complete\n",
    "train_performance <- well_folds_cv(data, train_svm)\n",
    "train_performance_round <- train_performance\n",
    "train_performance_round[,c(1,2,3,4,5)] <- round(train_performance[,c(1,2,3,4,5)],2)\n",
    "train_performance_round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting!  Our model seems to be performing in the 0.5 through 0.6 **F1-score** range with exception to the **Cross H Cattle** well (we'll worry about this in another notebook).  Let's average these out for an estimated model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>precision</dt>\n",
       "\t\t<dd>0.55</dd>\n",
       "\t<dt>recall</dt>\n",
       "\t\t<dd>0.51</dd>\n",
       "\t<dt>f1</dt>\n",
       "\t\t<dd>0.49</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[precision] 0.55\n",
       "\\item[recall] 0.51\n",
       "\\item[f1] 0.49\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "precision\n",
       ":   0.55recall\n",
       ":   0.51f1\n",
       ":   0.49\n",
       "\n"
      ],
      "text/plain": [
       "precision    recall        f1 \n",
       "     0.55      0.51      0.49 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(apply(train_performance[, c(3,4,5)], 2, mean),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests our training model has an average **F1-score** of 0.49.  Now let's apply the model to the blind data set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Applying the model to the blind data set  \n",
    "\n",
    "Here we will take the previously defined parameters and build a model using the training data and the tuned SVM parameters.  We will then output the overall **precision**, **recall**, and **F1-score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Overall Precision: 0.62\"\n",
      "[1] \"Overall Recall: 0.46\"\n",
      "[1] \"Overall F1-score: 0.43\"\n"
     ]
    }
   ],
   "source": [
    "set.seed(3124)\n",
    "\n",
    "# build model and predict facies\n",
    "fit <- svm(Facies ~ ., data=data[,-c(2,3,4)], kernel='radial', cost=15, gamma=.01)\n",
    "pred <- predict(fit, newdata=blind)\n",
    "\n",
    "# evaluate model\n",
    "cm <- confusionMatrix(pred, blind$Facies)\n",
    "metrics <- round(accuracy_metrics(as.matrix(cm[[\"table\"]]), blind$Facies),2)\n",
    "print(paste(\"Overall Precision:\", metrics[1]))\n",
    "print(paste(\"Overall Recall:\", metrics[2]))\n",
    "print(paste(\"Overall F1-score:\", metrics[3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 3.2",
   "language": "R",
   "name": "ir32"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
