{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Facies Determination with Regression\n",
    "\n",
    "As with the prior entries, this is a combination of brute-force feature creation and an ExtraTrees Regressor method. The aim of this is to capture more of the inter-dependancy of samples.\n",
    "I will freely admit that this is stretching my ML knowledge, I've spent quite a lot of time trying to ascertain whether this is a sensible thing to be doing at all. Comments and thoughts very welcome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"eafca1d6-b17f-4967-bf3f-6723fe7ff3ea\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = \"1\";\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      Bokeh.$(\"#eafca1d6-b17f-4967-bf3f-6723fe7ff3ea\").text(\"BokehJS successfully loaded.\");\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"eafca1d6-b17f-4967-bf3f-6723fe7ff3ea\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'eafca1d6-b17f-4967-bf3f-6723fe7ff3ea' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = ['https://cdn.pydata.org/bokeh/release/bokeh-0.12.3.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.3.min.js'];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      Bokeh.$(\"#eafca1d6-b17f-4967-bf3f-6723fe7ff3ea\").text(\"BokehJS is loading...\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.3.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.3.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.3.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.3.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === \"1\")) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === \"1\") {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (!force) {\n",
       "      var cell = $(\"#eafca1d6-b17f-4967-bf3f-6723fe7ff3ea\").parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import bokeh.plotting as bk\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tpot import TPOTClassifier, TPOTRegressor\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\george.crowther\\Documents\\Python\\Projects\\2016-ml-contest-master')\n",
    "\n",
    "import classification_utilities\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "bk.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input file paths\n",
    "train_path = r'..\\training_data.csv'\n",
    "\n",
    "# Read training data to dataframe\n",
    "train = pd.read_csv(train_path)\n",
    "\n",
    "# TPOT library requires that the target class is renamed to 'class'\n",
    "train.rename(columns={'Facies': 'class'}, inplace=True)\n",
    "\n",
    "well_names = train['Well Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set string features to integers\n",
    "\n",
    "for i, value in enumerate(train['Formation'].unique()):\n",
    "    train.loc[train['Formation'] == value, 'Formation'] = i\n",
    "    \n",
    "for i, value in enumerate(train['Well Name'].unique()):\n",
    "    train.loc[train['Well Name'] == value, 'Well Name'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The first thing that will be done is to upsample and interpolate the training data,\n",
    "# the objective here is to provide significantly more samples to train the regressor on and\n",
    "# also to capture more of the sample interdependancy.\n",
    "upsampled_arrays = []\n",
    "train['orig_index'] = train.index\n",
    "\n",
    "for well, group in train.groupby('Well Name'):\n",
    "    # This is a definite, but helpful, mis-use of the pandas resample timeseries\n",
    "    # functionality.\n",
    "    group.index = pd.to_datetime(group['Depth'] * 10)\n",
    "    # Upsampled by a factor of 5 and interpolate\n",
    "    us_group = group.resample('1ns').mean().interpolate(how='time')\n",
    "    # Revert to integer\n",
    "    us_group.index = us_group.index.asi8 / 10\n",
    "    us_group['Well Name'] = well\n",
    "    \n",
    "    upsampled_arrays.append(us_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "      <th>orig_index</th>\n",
       "      <th>Well Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2793.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2793.0</td>\n",
       "      <td>77.450</td>\n",
       "      <td>0.6640</td>\n",
       "      <td>9.90</td>\n",
       "      <td>11.915</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793.1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2793.1</td>\n",
       "      <td>77.612</td>\n",
       "      <td>0.6634</td>\n",
       "      <td>10.76</td>\n",
       "      <td>12.045</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793.2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2793.2</td>\n",
       "      <td>77.774</td>\n",
       "      <td>0.6628</td>\n",
       "      <td>11.62</td>\n",
       "      <td>12.175</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793.3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2793.3</td>\n",
       "      <td>77.936</td>\n",
       "      <td>0.6622</td>\n",
       "      <td>12.48</td>\n",
       "      <td>12.305</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9874</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793.4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2793.4</td>\n",
       "      <td>78.098</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>13.34</td>\n",
       "      <td>12.435</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class   Depth      GR  ILD_log10  DeltaPHI   PHIND   PE  NM_M  RELPOS  \\\n",
       "2793.0    3.0  2793.0  77.450     0.6640      9.90  11.915  4.6   1.0  1.0000   \n",
       "2793.1    3.0  2793.1  77.612     0.6634     10.76  12.045  4.5   1.0  0.9958   \n",
       "2793.2    3.0  2793.2  77.774     0.6628     11.62  12.175  4.4   1.0  0.9916   \n",
       "2793.3    3.0  2793.3  77.936     0.6622     12.48  12.305  4.3   1.0  0.9874   \n",
       "2793.4    3.0  2793.4  78.098     0.6616     13.34  12.435  4.2   1.0  0.9832   \n",
       "\n",
       "        orig_index  Well Name  \n",
       "2793.0         0.0          0  \n",
       "2793.1         0.2          0  \n",
       "2793.2         0.4          0  \n",
       "2793.3         0.6          0  \n",
       "2793.4         0.8          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled_arrays[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resample_factors = [2, 5, 10, 50, 100, 200]\n",
    "\n",
    "initial_columns = ['Formation', 'Well Name', 'Depth', 'GR', 'ILD_log10',\n",
    "       'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "\n",
    "upsampled_frame = pd.concat(upsampled_arrays, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use rolling windows through upsampled frame, grouping by well name.\n",
    "\n",
    "# Empty list to hold frames\n",
    "mean_frames = []\n",
    "\n",
    "for well, group in upsampled_frame.groupby('Well Name'):\n",
    "    # Empty list to hold rolling frames\n",
    "    constructor_list = []\n",
    "    for f in resample_factors:\n",
    "        \n",
    "        working_frame = group[['Depth', 'GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M',\n",
    "       'RELPOS', 'Well Name']]\n",
    "        \n",
    "        mean_frame = working_frame.rolling(window = f, center = True).mean().interpolate(method = 'index', limit_direction = 'both', limit = f)\n",
    "        mean_frame.columns = ['Mean_{0}_{1}'.format(f, column) for column in mean_frame.columns]\n",
    "        max_frame = working_frame.rolling(window = f, center = True).max().interpolate(method = 'index', limit_direction = 'both', limit = f)\n",
    "        max_frame.columns = ['Max_{0}_{1}'.format(f, column) for column in max_frame.columns]\n",
    "        min_frame = working_frame.rolling(window = f, center = True).min().interpolate(method = 'index', limit_direction = 'both', limit = f)\n",
    "        min_frame.columns = ['Min_{0}_{1}'.format(f, column) for column in min_frame.columns]\n",
    "        std_frame = working_frame.rolling(window = f, center = True).std().interpolate(method = 'index', limit_direction = 'both', limit = f)\n",
    "        std_frame.columns = ['Std_{0}_{1}'.format(f, column) for column in std_frame.columns]\n",
    "        var_frame = working_frame.rolling(window = f, center = True).var().interpolate(method = 'index', limit_direction = 'both', limit = f)\n",
    "        var_frame.columns = ['Var_{0}_{1}'.format(f, column) for column in var_frame.columns]\n",
    "        diff_frame = working_frame.diff(f, axis = 0).interpolate(method = 'index', limit_direction = 'both', limit = f)\n",
    "        diff_frame.columns = ['Diff_{0}_{1}'.format(f, column) for column in diff_frame.columns]\n",
    "        rdiff_frame = working_frame.sort_index(ascending = False).diff(f, axis = 0).interpolate(method = 'index', limit_direction = 'both', limit = f).sort_index()\n",
    "        rdiff_frame.columns = ['Rdiff_{0}_{1}'.format(f, column) for column in rdiff_frame.columns]\n",
    "        \n",
    "        f_frame = pd.concat((mean_frame, max_frame, min_frame, std_frame, var_frame, diff_frame, rdiff_frame), axis = 1)\n",
    "        \n",
    "        constructor_list.append(f_frame)\n",
    "        \n",
    "    well_frame = pd.concat(constructor_list, axis = 1)\n",
    "    well_frame['class'] = group['class']\n",
    "    well_frame['Well Name'] = group['Well Name']\n",
    "    # orig index is holding the original index locations, to make extracting the results trivial\n",
    "    well_frame['orig_index'] = group['orig_index']\n",
    "    mean_frames.append(well_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Depth', 'GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS',\n",
      "       'Mean_2_Depth', 'Mean_2_GR',\n",
      "       ...\n",
      "       'Diff_200_RELPOS', 'Diff_200_Well Name', 'Rdiff_200_Depth',\n",
      "       'Rdiff_200_GR', 'Rdiff_200_ILD_log10', 'Rdiff_200_DeltaPHI',\n",
      "       'Rdiff_200_PHIND', 'Rdiff_200_PE', 'Rdiff_200_NM_M',\n",
      "       'Rdiff_200_RELPOS'],\n",
      "      dtype='object', length=385)\n"
     ]
    }
   ],
   "source": [
    "upsampled_frame.index = upsampled_frame['orig_index']\n",
    "upsampled_frame.drop(['orig_index', 'class', 'Well Name'], axis = 1, inplace = True)\n",
    "\n",
    "for f in mean_frames:\n",
    "    f.index = f['orig_index']\n",
    "\n",
    "rolling_frame = pd.concat(mean_frames, axis = 0)\n",
    "upsampled_frame = pd.concat((upsampled_frame, rolling_frame), axis = 1)\n",
    "\n",
    "# Features is the column set used for training the model\n",
    "features = upsampled_frame.columns[:-4]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "exported_pipeline = make_pipeline(\n",
    "    ExtraTreesRegressor(max_features=0.27, n_estimators=500)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('extratreesregressor', ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "          max_features=0.27, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "          min_samples_leaf=1, min_samples_split=2,\n",
       "          min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "          oob_score=False, random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model to data\n",
    "exported_pipeline.fit(upsampled_frame[features], upsampled_frame['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load and process the test data set, then predict using the 'exported_pipeline' model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Depth', 'GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS',\n",
      "       'Mean_2_Depth', 'Mean_2_GR',\n",
      "       ...\n",
      "       'Diff_200_RELPOS', 'Diff_200_Well Name', 'Rdiff_200_Depth',\n",
      "       'Rdiff_200_GR', 'Rdiff_200_ILD_log10', 'Rdiff_200_DeltaPHI',\n",
      "       'Rdiff_200_PHIND', 'Rdiff_200_PE', 'Rdiff_200_NM_M',\n",
      "       'Rdiff_200_RELPOS'],\n",
      "      dtype='object', length=385)\n"
     ]
    }
   ],
   "source": [
    "test_path = r'..\\validation_data_nofacies.csv'\n",
    "\n",
    "# Read training data to dataframe\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "# TPOT library requires that the target class is renamed to 'class'\n",
    "test.rename(columns={'Facies': 'class'}, inplace=True)\n",
    "\n",
    "# Set string features to integers\n",
    "\n",
    "for i, value in enumerate(test['Formation'].unique()):\n",
    "    test.loc[train['Formation'] == value, 'Formation'] = i\n",
    "    \n",
    "for i, value in enumerate(test['Well Name'].unique()):\n",
    "    test.loc[test['Well Name'] == value, 'Well Name'] = i\n",
    "\n",
    "# The first thing that will be done is to upsample and interpolate the training data,\n",
    "# the objective here is to provide significantly more samples to train the regressor on and\n",
    "# also to capture more of the sample interdependancy.\n",
    "upsampled_arrays = []\n",
    "test['orig_index'] = test.index\n",
    "\n",
    "for well, group in test.groupby('Well Name'):\n",
    "    # This is a definite, but helpful, mis-use of the pandas resample timeseries\n",
    "    # functionality.\n",
    "    group.index = pd.to_datetime(group['Depth'] * 10)\n",
    "    # Upsampled by a factor of 5 and interpolate\n",
    "    us_group = group.resample('1ns').mean().interpolate(how='time')\n",
    "    # Revert to integer\n",
    "    us_group.index = us_group.index.asi8 / 10\n",
    "    us_group['Well Name'] = well\n",
    "    \n",
    "    upsampled_arrays.append(us_group)\n",
    "    \n",
    "upsampled_frame = pd.concat(upsampled_arrays, axis = 0)\n",
    "\n",
    "# Use rolling windows through upsampled frame, grouping by well name.\n",
    "\n",
    "# Empty list to hold frames\n",
    "mean_frames = []\n",
    "\n",
    "for well, group in upsampled_frame.groupby('Well Name'):\n",
    "    # Empty list to hold rolling frames\n",
    "    constructor_list = []\n",
    "    for f in resample_factors:\n",
    "        \n",
    "        working_frame = group[['Depth', 'GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M',\n",
    "       'RELPOS', 'Well Name']]\n",
    "        \n",
    "        mean_frame = working_frame.rolling(window = f, center = True).mean().interpolate(method = 'index', limit_direction = 'both', limit = f)\n",
    "        mean_frame.columns = ['Mean_{0}_{1}'.format(f, column) for column in mean_frame.columns]\n",
    "        max_frame = working_frame.rolling(window = f, center = True).max().interpolate(method = 'index', limit_direction = 'both', limit = f)\n",
    "        max_frame.columns = ['Max_{0}_{1}'.format(f, column) for column in max_frame.columns]\n",
    "        min_frame = working_frame.rolling(window = f, center = True).min().interpolate(method = 'index', limit_direction = 'both', limit = f)\n",
    "        min_frame.columns = ['Min_{0}_{1}'.format(f, column) for column in min_frame.columns]\n",
    "        std_frame = working_frame.rolling(window = f, center = True).std().interpolate(method = 'index', limit_direction = 'both', limit = f)\n",
    "        std_frame.columns = ['Std_{0}_{1}'.format(f, column) for column in std_frame.columns]\n",
    "        var_frame = working_frame.rolling(window = f, center = True).var().interpolate(method = 'index', limit_direction = 'both', limit = f)\n",
    "        var_frame.columns = ['Var_{0}_{1}'.format(f, column) for column in var_frame.columns]\n",
    "        diff_frame = working_frame.diff(f, axis = 0).interpolate(method = 'index', limit_direction = 'both', limit = f)\n",
    "        diff_frame.columns = ['Diff_{0}_{1}'.format(f, column) for column in diff_frame.columns]\n",
    "        rdiff_frame = working_frame.sort_index(ascending = False).diff(f, axis = 0).interpolate(method = 'index', limit_direction = 'both', limit = f).sort_index()\n",
    "        rdiff_frame.columns = ['Rdiff_{0}_{1}'.format(f, column) for column in rdiff_frame.columns]\n",
    "        \n",
    "        f_frame = pd.concat((mean_frame, max_frame, min_frame, std_frame, var_frame, diff_frame, rdiff_frame), axis = 1)\n",
    "        \n",
    "        constructor_list.append(f_frame)\n",
    "        \n",
    "    well_frame = pd.concat(constructor_list, axis = 1)\n",
    "    well_frame['Well Name'] = group['Well Name']\n",
    "    # orig index is holding the original index locations, to make extracting the results trivial\n",
    "    well_frame['orig_index'] = group['orig_index']\n",
    "    mean_frames.append(well_frame)\n",
    "    \n",
    "upsampled_frame.index = upsampled_frame['orig_index']\n",
    "upsampled_frame.drop(['orig_index', 'Well Name'], axis = 1, inplace = True)\n",
    "\n",
    "for f in mean_frames:\n",
    "    f.index = f['orig_index']\n",
    "\n",
    "rolling_frame = pd.concat(mean_frames, axis = 0)\n",
    "upsampled_frame = pd.concat((upsampled_frame, rolling_frame), axis = 1)\n",
    "\n",
    "tfeatures = upsampled_frame.columns[:-3]\n",
    "print(tfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict result on full sample set\n",
    "result = exported_pipeline.predict(upsampled_frame[tfeatures])\n",
    "# Round result to nearest int\n",
    "upsampled_frame['Facies'] = [round(n) for n in result]\n",
    "# Extract results against test index\n",
    "result_frame = upsampled_frame.loc[test.index, :]\n",
    "# Output to csv\n",
    "result_frame.to_csv('regressor_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:optasense]",
   "language": "python",
   "name": "conda-env-optasense-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
