{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contest entry by Wouter Kimman \n",
    "\n",
    "\n",
    "Strategy: \n",
    "----------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.fft import rfft\n",
    "from scipy import signal\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import timeit\n",
    "from sqlalchemy.sql import text\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "\n",
    "#from sklearn import cross_validation\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "#import sherlock.filesystem as sfs\n",
    "#import sherlock.database as sdb\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filename = 'training_data.csv'\n",
    "filename = 'facies_vectors.csv'\n",
    "training_data0 = pd.read_csv(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def magic(df):\n",
    "    df1=df.copy()\n",
    "    b, a = signal.butter(2, 0.2, btype='high', analog=False)\n",
    "    feats0=['GR','ILD_log10','DeltaPHI','PHIND','PE','NM_M','RELPOS']\n",
    "    #feats01=['GR','ILD_log10','DeltaPHI','PHIND']\n",
    "    #feats01=['DeltaPHI']\n",
    "    #feats01=['GR','DeltaPHI','PHIND']\n",
    "    feats01=['GR',]\n",
    "    feats02=['PHIND']\n",
    "    #feats02=[]\n",
    "    for ii in feats0:\n",
    "        df1[ii]=df[ii]\n",
    "        name1=ii + '_1'\n",
    "        name2=ii + '_2'\n",
    "        name3=ii + '_3'\n",
    "        name4=ii + '_4'\n",
    "        name5=ii + '_5'\n",
    "        name6=ii + '_6'\n",
    "        name7=ii + '_7'\n",
    "        name8=ii + '_8'\n",
    "        name9=ii + '_9'\n",
    "        xx1 = list(df[ii])\n",
    "        xx_mf= signal.medfilt(xx1,9)\n",
    "        x_min1=np.roll(xx_mf, 1)\n",
    "        x_min2=np.roll(xx_mf, -1)\n",
    "        x_min3=np.roll(xx_mf, 3)\n",
    "        x_min4=np.roll(xx_mf, 4)\n",
    "        xx1a=xx1-np.mean(xx1)\n",
    "        xx_fil = signal.filtfilt(b, a, xx1)        \n",
    "        xx_grad=np.gradient(xx1a) \n",
    "        x_min5=np.roll(xx_grad, 3)\n",
    "        #df1[name4]=xx_mf\n",
    "        if ii in feats01: \n",
    "            df1[name1]=x_min3\n",
    "            df1[name2]=xx_fil\n",
    "            df1[name3]=xx_grad\n",
    "            df1[name4]=xx_mf \n",
    "            df1[name5]=x_min1\n",
    "            df1[name6]=x_min2\n",
    "            df1[name7]=x_min4\n",
    "            #df1[name8]=x_min5\n",
    "            #df1[name9]=x_min2\n",
    "        if ii in feats02:\n",
    "            df1[name1]=x_min3\n",
    "            df1[name2]=xx_fil\n",
    "            df1[name3]=xx_grad\n",
    "            #df1[name4]=xx_mf \n",
    "            df1[name5]=x_min1\n",
    "            #df1[name6]=x_min2 \n",
    "            #df1[name7]=x_min4\n",
    "    return df1\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SHRIMPLIN' 'ALEXANDER D' 'SHANKLE' 'LUKE G U' 'KIMZEY A' 'CROSS H CATTLE'\n",
      " 'NOLAN' 'Recruit F9' 'NEWBY' 'CHURCHMAN BIBLE']\n"
     ]
    }
   ],
   "source": [
    "all_wells=training_data0['Well Name'].unique()\n",
    "print all_wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5515\n",
      "SHRIMPLIN\n",
      "471\n",
      "using median of local\n",
      "ALEXANDER D\n",
      "466\n",
      "using median of total\n",
      "SHANKLE\n",
      "449\n",
      "using median of local\n",
      "LUKE G U\n",
      "461\n",
      "using median of local\n",
      "KIMZEY A\n",
      "439\n",
      "using median of total\n",
      "CROSS H CATTLE\n",
      "501\n",
      "using median of local\n",
      "NOLAN\n",
      "415\n",
      "using median of local\n",
      "Recruit F9\n",
      "80\n",
      "using median of local\n",
      "NEWBY\n",
      "463\n",
      "using median of local\n",
      "CHURCHMAN BIBLE\n",
      "404\n",
      "using median of local\n",
      "4149\n",
      "4149\n"
     ]
    }
   ],
   "source": [
    "# what to do with the naans\n",
    "training_data1=training_data0.copy()\n",
    "me_tot=training_data1['PE'].median()\n",
    "print me_tot\n",
    "for well in all_wells:\n",
    "    df=training_data0[training_data0['Well Name'] == well] \n",
    "    print well\n",
    "    print len(df)\n",
    "    df0=df.dropna()\n",
    "    #print len(df0)\n",
    "    if len(df0) > 0:\n",
    "        print \"using median of local\"\n",
    "        me=df['PE'].median()\n",
    "        df=df.fillna(value=me)\n",
    "    else:\n",
    "        print \"using median of total\"\n",
    "        df=df.fillna(value=me_tot)\n",
    "    training_data1[training_data0['Well Name'] == well] =df\n",
    "    \n",
    "\n",
    "print len(training_data1)\n",
    "df0=training_data1.dropna()\n",
    "print len(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4149\n",
      "4149\n",
      "4149\n",
      "4143\n"
     ]
    }
   ],
   "source": [
    "#remove outliers\n",
    "df=training_data1.copy()\n",
    "print len(df)\n",
    "df0=df.dropna()\n",
    "print len(df0)\n",
    "df1 = df0.drop(['Formation', 'Well Name', 'Depth','Facies'], axis=1)\n",
    "#df=pd.DataFrame(np.random.randn(20,3))\n",
    "#df.iloc[3,2]=5\n",
    "print len(df1)\n",
    "df2=df0[(np.abs(stats.zscore(df1))<8).all(axis=1)]\n",
    "print len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_test(remove_well, df_train):\n",
    "    \n",
    "    df_test=training_data2\n",
    "    blind = df_test[df_test['Well Name'] == remove_well]      \n",
    "    training_data = df_train[df_train['Well Name'] != remove_well]  \n",
    "    \n",
    "    correct_facies_labels_train = training_data['Facies'].values\n",
    "    feature_vectors = training_data.drop(['Formation', 'Well Name', 'Depth','Facies'], axis=1)\n",
    "    #rf = RandomForestClassifier(max_depth = 15, n_estimators=600) \n",
    "    #rf = RandomForestClassifier(max_depth = 7, n_estimators=600)  \n",
    "    rf = RandomForestClassifier(max_depth = 5, n_estimators=300,min_samples_leaf=15)\n",
    "    rf.fit(feature_vectors, correct_facies_labels_train)\n",
    "\n",
    "    correct_facies_labels = blind['Facies'].values\n",
    "    features_blind = blind.drop(['Formation', 'Well Name', 'Depth','Facies'], axis=1)\n",
    "    scaler = preprocessing.StandardScaler().fit(feature_vectors)\n",
    "    scaled_features =feature_vectors\n",
    "    predicted_random_forest = rf.predict(features_blind)\n",
    "\n",
    "    out_f1=metrics.f1_score(correct_facies_labels, predicted_random_forest,average = 'micro')\n",
    "    return out_f1\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "training_data2=magic(training_data1)\n",
    "df_train=training_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well : CHURCHMAN BIBLE, f1 for different runs:\n",
      "average f1 is 0.540594, 2*std is 0.006715\n",
      "well : SHANKLE, f1 for different runs:\n",
      "average f1 is 0.546993, 2*std is 0.013393\n",
      "well : NOLAN, f1 for different runs:\n",
      "average f1 is 0.578795, 2*std is 0.014426\n",
      "well : NEWBY, f1 for different runs:\n",
      "average f1 is 0.560259, 2*std is 0.010439\n",
      "well : Recruit F9, f1 for different runs:\n",
      "average f1 is 0.487500, 2*std is 0.075829\n",
      "well : CROSS H CATTLE, f1 for different runs:\n",
      "average f1 is 0.328543, 2*std is 0.033836\n",
      "well : LUKE G U, f1 for different runs:\n",
      "average f1 is 0.637310, 2*std is 0.012393\n",
      "well : SHRIMPLIN, f1 for different runs:\n",
      "average f1 is 0.595329, 2*std is 0.005760\n",
      "overall average f1 is 0.534415\n"
     ]
    }
   ],
   "source": [
    "wells=['CHURCHMAN BIBLE','SHANKLE','NOLAN','NEWBY','Recruit F9' ,'CROSS H CATTLE','LUKE G U','SHRIMPLIN']\n",
    "av_all=[]\n",
    "for remove_well in wells:\n",
    "    all=[]\n",
    "    print(\"well : %s, f1 for different runs:\" % (remove_well))\n",
    "    for ii in range(5):\n",
    "        out_f1=run_test(remove_well,df_train)   \n",
    "        if remove_well is not 'Recruit F9':\n",
    "            all.append(out_f1)        \n",
    "    av1=np.mean(all) \n",
    "    av_all.append(av1)\n",
    "    print(\"average f1 is %f, 2*std is %f\" % (av1, 2*np.std(all)) )\n",
    "print(\"overall average f1 is %f\" % (np.mean(av_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train for the test data\n",
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = 'validation_data_nofacies.csv'\n",
    "test_data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data1=magic(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_well='STUART'\n",
    "test_well='CRAWFORD'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blind = test_data1[test_data1['Well Name'] == test_well]      \n",
    "training_data = training_data2\n",
    "\n",
    "correct_facies_labels_train = training_data['Facies'].values\n",
    "feature_vectors = training_data.drop(['Formation', 'Well Name', 'Depth','Facies'], axis=1)\n",
    "rf = RandomForestClassifier(max_depth = 14, n_estimators=2500,min_samples_leaf=15) \n",
    "rf.fit(feature_vectors, correct_facies_labels_train)\n",
    "\n",
    "features_blind = blind.drop(['Formation', 'Well Name', 'Depth'], axis=1)\n",
    "predicted_random_forest = rf.predict(features_blind)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 8, 8, 8,\n",
       "       8, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 7, 9, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 7, 7, 7, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 2, 2,\n",
       "       2, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 2, 2, 2,\n",
       "       3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n",
       "       3, 3, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 3, 3, 3, 2, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8, 8, 8, 6, 6, 6, 8, 8, 8, 8, 9, 9,\n",
       "       9, 8, 8, 8, 8, 8, 6, 6, 6, 6, 6, 8, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 3, 3, 3, 3, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 4,\n",
       "       4, 4, 4, 4, 4, 8, 4, 4, 4, 4, 8, 8, 4, 4, 8, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_stu=predicted_random_forest\n",
    "predicted_stu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 8, 7, 7, 7, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 8,\n",
       "       8, 8, 8, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 8, 8, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 8, 3, 2, 6, 8, 8, 8, 6, 6, 6, 5, 6, 5, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       8, 8, 8, 8, 8, 6, 6, 8, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 3, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7,\n",
       "       7, 7, 7, 7, 8, 8, 8, 8, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 3, 3, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n",
       "       3, 3, 3, 8, 8, 8, 8, 8, 8, 8, 8, 6, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 1,\n",
       "       1, 1, 1, 7, 7, 7, 7, 7, 8, 8, 8, 8, 7, 7, 7, 7, 1, 1, 7, 7, 7, 7, 7,\n",
       "       7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 6, 6, 8, 8, 3, 3, 3, 3, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_craw=predicted_random_forest\n",
    "predicted_craw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
