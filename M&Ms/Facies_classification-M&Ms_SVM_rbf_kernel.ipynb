{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facies classification using Machine Learning\n",
    "\n",
    "\n",
    "### Contest entry by Matteo Niccoli and Mark Dahl\n",
    "\n",
    "\n",
    "#### Based on [the original notebook](../Facies_classification.ipynb) by Brendon Hall, [Enthought](https://www.enthought.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to train a machine learning algorithm to predict facies from well log data.  The dataset we will use comes from a class excercise from The University of Kansas on [Neural Networks and Fuzzy Systems](http://www.people.ku.edu/~gbohling/EECS833/).  This exercise is based on a consortium project to use machine learning techniques to create a reservoir model of the largest gas fields in North America, the Hugoton and Panoma Fields. For more info on the origin of the data, see [Bohling and Dubois (2003)](http://www.kgs.ku.edu/PRS/publication/2003/ofr2003-50.pdf) and [Dubois et al. (2007)](http://dx.doi.org/10.1016/j.cageo.2006.08.011). \n",
    "\n",
    "The dataset we will use is log data from nine wells that have been labeled with a facies type based on oberservation of core.  We will use this log data to train a support vector machine to classify facies types.  Support vector machines (or SVMs) are a type of supervised learning model that can be trained on data to perform classification and regression tasks.  The SVM algorithm uses the training data to fit an optimal hyperplane between the different classes (or facies, in our case).  We will use the SVM implementation in [scikit-learn](http://scikit-learn.org/stable/modules/svm.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the dataset\n",
    "\n",
    "First, we will examine the data set we will use to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score, accuracy_score, make_scorer\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut, validation_curve\n",
    "import pandas as pd\n",
    "from pandas import set_option\n",
    "set_option(\"display.max_rows\", 10)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Formation</th>\n",
       "      <th>Well Name</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.0</td>\n",
       "      <td>77.450</td>\n",
       "      <td>0.664</td>\n",
       "      <td>9.900</td>\n",
       "      <td>11.915</td>\n",
       "      <td>4.600</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.5</td>\n",
       "      <td>78.260</td>\n",
       "      <td>0.661</td>\n",
       "      <td>14.200</td>\n",
       "      <td>12.565</td>\n",
       "      <td>4.100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.0</td>\n",
       "      <td>79.050</td>\n",
       "      <td>0.658</td>\n",
       "      <td>14.800</td>\n",
       "      <td>13.050</td>\n",
       "      <td>3.600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.5</td>\n",
       "      <td>86.100</td>\n",
       "      <td>0.655</td>\n",
       "      <td>13.900</td>\n",
       "      <td>13.115</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2795.0</td>\n",
       "      <td>74.580</td>\n",
       "      <td>0.647</td>\n",
       "      <td>13.500</td>\n",
       "      <td>13.300</td>\n",
       "      <td>3.400</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>5</td>\n",
       "      <td>C LM</td>\n",
       "      <td>CHURCHMAN BIBLE</td>\n",
       "      <td>3120.5</td>\n",
       "      <td>46.719</td>\n",
       "      <td>0.947</td>\n",
       "      <td>1.828</td>\n",
       "      <td>7.254</td>\n",
       "      <td>3.617</td>\n",
       "      <td>2</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>5</td>\n",
       "      <td>C LM</td>\n",
       "      <td>CHURCHMAN BIBLE</td>\n",
       "      <td>3121.0</td>\n",
       "      <td>44.563</td>\n",
       "      <td>0.953</td>\n",
       "      <td>2.241</td>\n",
       "      <td>8.013</td>\n",
       "      <td>3.344</td>\n",
       "      <td>2</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>5</td>\n",
       "      <td>C LM</td>\n",
       "      <td>CHURCHMAN BIBLE</td>\n",
       "      <td>3121.5</td>\n",
       "      <td>49.719</td>\n",
       "      <td>0.964</td>\n",
       "      <td>2.925</td>\n",
       "      <td>8.013</td>\n",
       "      <td>3.190</td>\n",
       "      <td>2</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>5</td>\n",
       "      <td>C LM</td>\n",
       "      <td>CHURCHMAN BIBLE</td>\n",
       "      <td>3122.0</td>\n",
       "      <td>51.469</td>\n",
       "      <td>0.965</td>\n",
       "      <td>3.083</td>\n",
       "      <td>7.708</td>\n",
       "      <td>3.152</td>\n",
       "      <td>2</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>5</td>\n",
       "      <td>C LM</td>\n",
       "      <td>CHURCHMAN BIBLE</td>\n",
       "      <td>3122.5</td>\n",
       "      <td>50.031</td>\n",
       "      <td>0.970</td>\n",
       "      <td>2.609</td>\n",
       "      <td>6.668</td>\n",
       "      <td>3.295</td>\n",
       "      <td>2</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4149 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Facies Formation        Well Name   Depth      GR  ILD_log10  DeltaPHI  \\\n",
       "0          3     A1 SH        SHRIMPLIN  2793.0  77.450      0.664     9.900   \n",
       "1          3     A1 SH        SHRIMPLIN  2793.5  78.260      0.661    14.200   \n",
       "2          3     A1 SH        SHRIMPLIN  2794.0  79.050      0.658    14.800   \n",
       "3          3     A1 SH        SHRIMPLIN  2794.5  86.100      0.655    13.900   \n",
       "4          3     A1 SH        SHRIMPLIN  2795.0  74.580      0.647    13.500   \n",
       "...      ...       ...              ...     ...     ...        ...       ...   \n",
       "4144       5      C LM  CHURCHMAN BIBLE  3120.5  46.719      0.947     1.828   \n",
       "4145       5      C LM  CHURCHMAN BIBLE  3121.0  44.563      0.953     2.241   \n",
       "4146       5      C LM  CHURCHMAN BIBLE  3121.5  49.719      0.964     2.925   \n",
       "4147       5      C LM  CHURCHMAN BIBLE  3122.0  51.469      0.965     3.083   \n",
       "4148       5      C LM  CHURCHMAN BIBLE  3122.5  50.031      0.970     2.609   \n",
       "\n",
       "       PHIND     PE  NM_M  RELPOS  \n",
       "0     11.915  4.600     1   1.000  \n",
       "1     12.565  4.100     1   0.979  \n",
       "2     13.050  3.600     1   0.957  \n",
       "3     13.115  3.500     1   0.936  \n",
       "4     13.300  3.400     1   0.915  \n",
       "...      ...    ...   ...     ...  \n",
       "4144   7.254  3.617     2   0.685  \n",
       "4145   8.013  3.344     2   0.677  \n",
       "4146   8.013  3.190     2   0.669  \n",
       "4147   7.708  3.152     2   0.661  \n",
       "4148   6.668  3.295     2   0.653  \n",
       "\n",
       "[4149 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../facies_vectors.csv'\n",
    "training_data = pd.read_csv(filename)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is from the Council Grove gas reservoir in Southwest Kansas.  The Panoma Council Grove Field is predominantly a carbonate gas reservoir encompassing 2700 square miles in Southwestern Kansas.  This dataset is from nine wells (with 4149 examples), consisting of a set of seven predictor variables and a rock facies (class) for each example vector and validation (test) data (830 examples from two wells) having the same seven predictor variables in the feature vector.  Facies are based on examination of cores from nine wells taken vertically at half-foot intervals. Predictor variables include five from wireline log measurements and two geologic constraining variables that are derived from geologic knowledge. These are essentially continuous variables sampled at a half-foot sample rate. \n",
    "\n",
    "The seven predictor variables are:\n",
    "* Five wire line log curves include [gamma ray](http://petrowiki.org/Gamma_ray_logs) (GR), [resistivity logging](http://petrowiki.org/Resistivity_and_spontaneous_%28SP%29_logging) (ILD_log10),\n",
    "[photoelectric effect](http://www.glossary.oilfield.slb.com/en/Terms/p/photoelectric_effect.aspx) (PE), [neutron-density porosity difference and average neutron-density porosity](http://petrowiki.org/Neutron_porosity_logs) (DeltaPHI and PHIND). Note, some wells do not have PE.\n",
    "* Two geologic constraining variables: nonmarine-marine indicator (NM_M) and relative position (RELPOS)\n",
    "\n",
    "The nine discrete facies (classes of rocks) are: \n",
    "1. Nonmarine sandstone\n",
    "2. Nonmarine coarse siltstone \n",
    "3. Nonmarine fine siltstone \n",
    "4. Marine siltstone and shale \n",
    "5. Mudstone (limestone)\n",
    "6. Wackestone (limestone)\n",
    "7. Dolomite\n",
    "8. Packstone-grainstone (limestone)\n",
    "9. Phylloid-algal bafflestone (limestone)\n",
    "\n",
    "These facies aren't discrete, and gradually blend into one another. Some have neighboring facies that are rather close.  Mislabeling within these neighboring facies can be expected to occur.  The following table lists the facies, their abbreviated labels and their approximate neighbors.\n",
    "\n",
    "Facies |Label| Adjacent Facies\n",
    ":---: | :---: |:--:\n",
    "1 |SS| 2\n",
    "2 |CSiS| 1,3\n",
    "3 |FSiS| 2\n",
    "4 |SiSh| 5\n",
    "5 |MS| 4,6\n",
    "6 |WS| 5,7\n",
    "7 |D| 6,8\n",
    "8 |PS| 6,7,9\n",
    "9 |BS| 7,8\n",
    "\n",
    "Let's clean up this dataset.  The 'Well Name' and 'Formation' columns can be turned into a categorical data type.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SHRIMPLIN, ALEXANDER D, SHANKLE, LUKE G U, KIMZEY A, CROSS H CATTLE, NOLAN, Recruit F9, NEWBY, CHURCHMAN BIBLE]\n",
       "Categories (10, object): [SHRIMPLIN, ALEXANDER D, SHANKLE, LUKE G U, ..., NOLAN, Recruit F9, NEWBY, CHURCHMAN BIBLE]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Well Name'] = training_data['Well Name'].astype('category')\n",
    "training_data['Formation'] = training_data['Formation'].astype('category')\n",
    "training_data['Well Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the names of the 10 training wells in the Council Grove reservoir.  Data has been recruited into pseudo-well 'Recruit F9' to better represent facies 9, the Phylloid-algal bafflestone. \n",
    "\n",
    "Before we plot the well data, let's define a color map so the facies are represented by consistent color in all the plots in this tutorial.  We also create the abbreviated facies labels, and add those to the `facies_vectors` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>3232.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.503254</td>\n",
       "      <td>2906.867438</td>\n",
       "      <td>64.933985</td>\n",
       "      <td>0.659566</td>\n",
       "      <td>4.402484</td>\n",
       "      <td>13.201066</td>\n",
       "      <td>3.725014</td>\n",
       "      <td>1.518438</td>\n",
       "      <td>0.521852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.474324</td>\n",
       "      <td>133.300164</td>\n",
       "      <td>30.302530</td>\n",
       "      <td>0.252703</td>\n",
       "      <td>5.274947</td>\n",
       "      <td>7.132846</td>\n",
       "      <td>0.896152</td>\n",
       "      <td>0.499720</td>\n",
       "      <td>0.286644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2573.500000</td>\n",
       "      <td>10.149000</td>\n",
       "      <td>-0.025949</td>\n",
       "      <td>-21.832000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2821.500000</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>0.498000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.277000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2932.500000</td>\n",
       "      <td>64.990000</td>\n",
       "      <td>0.639000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>3.551500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>3007.000000</td>\n",
       "      <td>79.438000</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>16.050000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.769000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3138.000000</td>\n",
       "      <td>361.150000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>19.312000</td>\n",
       "      <td>84.400000</td>\n",
       "      <td>8.094000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Facies        Depth           GR    ILD_log10     DeltaPHI  \\\n",
       "count  4149.000000  4149.000000  4149.000000  4149.000000  4149.000000   \n",
       "mean      4.503254  2906.867438    64.933985     0.659566     4.402484   \n",
       "std       2.474324   133.300164    30.302530     0.252703     5.274947   \n",
       "min       1.000000  2573.500000    10.149000    -0.025949   -21.832000   \n",
       "25%       2.000000  2821.500000    44.730000     0.498000     1.600000   \n",
       "50%       4.000000  2932.500000    64.990000     0.639000     4.300000   \n",
       "75%       6.000000  3007.000000    79.438000     0.822000     7.500000   \n",
       "max       9.000000  3138.000000   361.150000     1.800000    19.312000   \n",
       "\n",
       "             PHIND           PE         NM_M       RELPOS  \n",
       "count  4149.000000  3232.000000  4149.000000  4149.000000  \n",
       "mean     13.201066     3.725014     1.518438     0.521852  \n",
       "std       7.132846     0.896152     0.499720     0.286644  \n",
       "min       0.550000     0.200000     1.000000     0.000000  \n",
       "25%       8.500000     3.100000     1.000000     0.277000  \n",
       "50%      12.020000     3.551500     2.000000     0.528000  \n",
       "75%      16.050000     4.300000     2.000000     0.769000  \n",
       "max      84.400000     8.094000     2.000000     1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1=sandstone  2=c_siltstone   3=f_siltstone # 4=marine_silt_shale \n",
    "#5=mudstone 6=wackestone 7=dolomite 8=packstone 9=bafflestone\n",
    "facies_colors = ['#F4D03F', '#F5B041', '#DC7633','#A569BD',\n",
    "       '#000000', '#000080', '#2E86C1', '#AED6F1', '#196F3D']\n",
    "\n",
    "facies_labels = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS',\n",
    "                 'WS', 'D','PS', 'BS']\n",
    "#facies_color_map is a dictionary that maps facies labels\n",
    "#to their respective colors\n",
    "facies_color_map = {}\n",
    "for ind, label in enumerate(facies_labels):\n",
    "    facies_color_map[label] = facies_colors[ind]\n",
    "\n",
    "def label_facies(row, labels):\n",
    "    return labels[ row['Facies'] -1]\n",
    "    \n",
    "training_data.loc[:,'FaciesLabels'] = training_data.apply(lambda row: label_facies(row, facies_labels), axis=1)\n",
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a quick view of the statistical distribution of the input variables.  Looking at the `count` values, most values have 4149 valid values except for `PE`, which has 3232.  In this tutorial we will drop the feature vectors that don't have a valid `PE` entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PE_mask = training_data['PE'].notnull().values\n",
    "training_data = training_data[PE_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3232.000000</td>\n",
       "      <td>3232.000000</td>\n",
       "      <td>3232.000000</td>\n",
       "      <td>3232.000000</td>\n",
       "      <td>3232.000000</td>\n",
       "      <td>3232.000000</td>\n",
       "      <td>3232.000000</td>\n",
       "      <td>3232.000000</td>\n",
       "      <td>3232.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.422030</td>\n",
       "      <td>2875.824567</td>\n",
       "      <td>66.135769</td>\n",
       "      <td>0.642719</td>\n",
       "      <td>3.559642</td>\n",
       "      <td>13.483213</td>\n",
       "      <td>3.725014</td>\n",
       "      <td>1.498453</td>\n",
       "      <td>0.520287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.504243</td>\n",
       "      <td>131.006274</td>\n",
       "      <td>30.854826</td>\n",
       "      <td>0.241845</td>\n",
       "      <td>5.228948</td>\n",
       "      <td>7.698980</td>\n",
       "      <td>0.896152</td>\n",
       "      <td>0.500075</td>\n",
       "      <td>0.286792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2573.500000</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>-0.025949</td>\n",
       "      <td>-21.832000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2791.000000</td>\n",
       "      <td>46.918750</td>\n",
       "      <td>0.492750</td>\n",
       "      <td>1.163750</td>\n",
       "      <td>8.346750</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2893.500000</td>\n",
       "      <td>65.721500</td>\n",
       "      <td>0.624437</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>12.150000</td>\n",
       "      <td>3.551500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.526000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>2980.000000</td>\n",
       "      <td>79.626250</td>\n",
       "      <td>0.812735</td>\n",
       "      <td>6.432500</td>\n",
       "      <td>16.453750</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.767250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3122.500000</td>\n",
       "      <td>361.150000</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>84.400000</td>\n",
       "      <td>8.094000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Facies        Depth           GR    ILD_log10     DeltaPHI  \\\n",
       "count  3232.000000  3232.000000  3232.000000  3232.000000  3232.000000   \n",
       "mean      4.422030  2875.824567    66.135769     0.642719     3.559642   \n",
       "std       2.504243   131.006274    30.854826     0.241845     5.228948   \n",
       "min       1.000000  2573.500000    13.250000    -0.025949   -21.832000   \n",
       "25%       2.000000  2791.000000    46.918750     0.492750     1.163750   \n",
       "50%       4.000000  2893.500000    65.721500     0.624437     3.500000   \n",
       "75%       6.000000  2980.000000    79.626250     0.812735     6.432500   \n",
       "max       9.000000  3122.500000   361.150000     1.480000    18.600000   \n",
       "\n",
       "             PHIND           PE         NM_M       RELPOS  \n",
       "count  3232.000000  3232.000000  3232.000000  3232.000000  \n",
       "mean     13.483213     3.725014     1.498453     0.520287  \n",
       "std       7.698980     0.896152     0.500075     0.286792  \n",
       "min       0.550000     0.200000     1.000000     0.010000  \n",
       "25%       8.346750     3.100000     1.000000     0.273000  \n",
       "50%      12.150000     3.551500     1.000000     0.526000  \n",
       "75%      16.453750     4.300000     2.000000     0.767250  \n",
       "max      84.400000     8.094000     2.000000     1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract just the feature variables we need to perform the classification.  The predictor variables are the five log values and two geologic constraining variables, and depth. We also get a vector of the facies labels that correspond to each feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 2 2 2 2 2 2 3 3 3 3 3 3 3]\n",
      "(3232,)\n"
     ]
    }
   ],
   "source": [
    "y = training_data['Facies'].values\n",
    "print y[25:40]\n",
    "print np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3232, 8)\n"
     ]
    }
   ],
   "source": [
    "X = training_data.drop(['Formation', 'Well Name','Facies','FaciesLabels'], axis=1)\n",
    "X.describe(percentiles=[.05, .25, .50, .75, .95])\n",
    "print np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Stratified K-fold validation to evaluate model performance \n",
    "One of the key steps in machine learning is to estimate a model's performance on data that it has not seen before.\n",
    "Scikit-learn provides a simple utility utility (train_test_split) to partition the data into a training and a test set, but the disadvantage with that is that we ignore a portion of our dataset during training. An additional disadvantage of simple spit, inherent to log data, is that there's a depth dependence. \n",
    "\n",
    "A possible strategy to avoid this is cross-validation. With k-fold cross-validation we randomly split the data into k-folds without replacement, where k-1 folds are used for training and one fold for testing. The process is repeated k times, and the performance is obtained by taking the average of the k individual performances.\n",
    "\n",
    "Stratified k-fold is an improvement over standard k-fold in that the class proportions are preserved in each fold to ensure that each fold is representative of the class proportions in the data.\n",
    "\n",
    "### Grid search for parameter tuning\n",
    "\n",
    "Another important aspect of machine learning is the search for the optimal model parameters (i.e. those that will yield the best performance). This tuning is done using grid search.\n",
    "\n",
    "The above short summary is based on Sebastian Raschka's <a href=\"https://github.com/rasbt/python-machine-learning-book\"> Python Machine Learning</a> book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make performance scorers\n",
    "Used to  evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Fscorer = make_scorer(f1_score, average = 'micro')\n",
    "Ascorer = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two birds with a stone\n",
    "\n",
    "Grid search with stratified K-fold: http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_digits.html#sphx-glr-auto-examples-model-selection-grid-search-digits-py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SVM classifier\n",
    "Very much like the classifier in the article. We will re-import the data so as to preprocess it as in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "SVC_classifier = svm.SVC(cache_size = 500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('../training_data.csv')\n",
    "X = training_data.drop(['Formation', 'Well Name', 'Facies'], axis=1).values\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "y = training_data['Facies'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.540532178218\n",
      "Best parameters: {'kernel': 'rbf', 'C': 5, 'gamma': 0.01}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=5, cache_size=500, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parm_grid={'kernel': ['linear', 'rbf'],\n",
    "            'C': [0.5, 1, 5, 10, 15],\n",
    "            'gamma':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(SVC_classifier,\n",
    "                           param_grid=parm_grid,\n",
    "                           scoring = Fscorer,\n",
    "                           cv=10) # Stratified K-fold with n_splits=10\n",
    "                                  # For integer inputs, if the estimator is a\n",
    "                                  # classifier and y is either binary or multiclass,\n",
    "                                  # as in our case, StratifiedKFold is used\n",
    "            \n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves\n",
    "\n",
    "Adapted from: http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(0.1, 1., 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring = Ascorer)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training accuracy\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation accuracy\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, how many samples do we have for each leave-one-well-out split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHURCHMAN BIBLE out:  2828 training samples -  404 test samples\n",
      "CROSS H CATTLE out:  2731 training samples -  501 test samples\n",
      "LUKE G U out:  2771 training samples -  461 test samples\n",
      "NEWBY out:  2769 training samples -  463 test samples\n",
      "NOLAN out:  2817 training samples -  415 test samples\n",
      "Recruit F9 out:  3164 training samples -  68 test samples\n",
      "SHANKLE out:  2783 training samples -  449 test samples\n",
      "SHRIMPLIN out:  2761 training samples -  471 test samples\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv('../training_data.csv')\n",
    "X = training_data.drop(['Formation', 'Well Name', 'Facies'], axis=1).values\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "y = training_data['Facies'].values\n",
    "wells = training_data[\"Well Name\"].values\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "for train, test in logo.split(X, y, groups=wells):\n",
    "    well_name = wells[test[0]]\n",
    "    print well_name, 'out: ', np.shape(train)[0], 'training samples - ', np.shape(test)[0], 'test samples'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "SVC_classifier = svm.SVC(C=5, cache_size=500, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma=0.1, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
    "  tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('../training_data.csv')\n",
    "X = training_data.drop(['Formation', 'Well Name', 'Facies'], axis=1).values\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "y = training_data['Facies'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEZCAYAAACEkhK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11833d550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = \"Learning Curves (SVC)\"\n",
    "# Cross validation with 50 iterations to get smoother mean test and train\n",
    "# score curves, each time with 15% data randomly selected as a validation set.\n",
    "# this is equivalent to leaving out one well, on average (3232 minus ~2750 samples)\n",
    "cv = ShuffleSplit(n_splits=50, test_size=0.15, random_state=1)\n",
    "\n",
    "plot_learning_curve(SVC_classifier, title, X, y, cv=cv, ylim=(0.4, 1.01), n_jobs=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps very slightly overfit: a bit of varianace / separation between the two errors, but not a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "SVC_classifier_conf = svm.SVC(C=5, cache_size=500, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma=0.01, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
    "  tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pred    SS  CSiS  FSiS  SiSh    MS    WS     D    PS    BS Total\n",
      "     True\n",
      "       SS   139    37    16                                       192\n",
      "     CSiS   118   550   199     4     6     1           6         884\n",
      "     FSiS     2   145   385     1     5     1     1     6         546\n",
      "     SiSh                 7   115    26    30    14    13     7   212\n",
      "       MS                       6    14     5     2    14          41\n",
      "       WS           2     3    51   126   323     9   118     9   641\n",
      "        D                       2     6     5    47     3          63\n",
      "       PS           4     5     5    34    96    25   322    33   524\n",
      "       BS                                   1          16   112   129\n",
      "\n",
      "Precision  0.54  0.75  0.63  0.62  0.06  0.70  0.48  0.65  0.70  0.66\n",
      "   Recall  0.72  0.62  0.71  0.54  0.34  0.50  0.75  0.61  0.87  0.62\n",
      "       F1  0.62  0.68  0.66  0.58  0.11  0.59  0.58  0.63  0.77  0.63\n"
     ]
    }
   ],
   "source": [
    "svc_pred = SVC_classifier_conf.fit(X,y)\n",
    "svc_pred = SVC_classifier_conf.predict(X)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from classification_utilities import display_cm, display_adj_cm\n",
    "\n",
    "conf = confusion_matrix(svc_pred, y)\n",
    "display_cm(conf, facies_labels, display_metrics=True, hide_zeros=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "SVC_classifier_LOO = svm.SVC(C=5, cache_size=500, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma=0.01, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
    "  tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CHURCHMAN BIBLE  0.507\n",
      "      CROSS H CATTLE  0.345\n",
      "            LUKE G U  0.449\n",
      "               NEWBY  0.395\n",
      "               NOLAN  0.523\n",
      "          Recruit F9  0.632\n",
      "             SHANKLE  0.501\n",
      "           SHRIMPLIN  0.556\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv('../training_data.csv')\n",
    "X = training_data.drop(['Formation', 'Well Name', 'Facies'], axis=1).values\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "y = training_data['Facies'].values\n",
    "wells = training_data[\"Well Name\"].values\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "f1_SVC = []\n",
    "\n",
    "for train, test in logo.split(X, y, groups=wells):\n",
    "    well_name = wells[test[0]]\n",
    "    SVC_classifier_LOO.fit(X[train], y[train])\n",
    "    pred = SVC_classifier_LOO.predict(X[test])\n",
    "    sc = f1_score(y[test], pred, labels = np.arange(10), average = 'micro')\n",
    "    print(\"{:>20s}  {:.3f}\".format(well_name, sc))\n",
    "    f1_SVC.append(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Average leave-one-out F1 Score: 0.558518\n"
     ]
    }
   ],
   "source": [
    "print \"-Average leave-one-out F1 Score: %6f\" % (sum(f1_SVC)/(1.0*(len(f1_SVC)-1)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
