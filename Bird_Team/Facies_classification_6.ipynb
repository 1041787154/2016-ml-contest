{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facies classification using Machine Learning\n",
    "\n",
    "#### Bird Team: PG+AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict, LeaveOneGroupOut, LeavePGroupsOut\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, f1_score, accuracy_score, recall_score, precision_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel, RFECV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from stacking_classifiers import *\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['SHRIMPLIN', 'Recruit F9', 'ALEXANDER D', 'SHANKLE', 'CHURCHMAN BIBLE', 'NOLAN', 'KIMZEY A', 'NEWBY', 'LUKE G U', 'CROSS H CATTLE'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Formation</th>\n",
       "      <th>Well Name</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.0</td>\n",
       "      <td>77.45</td>\n",
       "      <td>0.664</td>\n",
       "      <td>9.9</td>\n",
       "      <td>11.915</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.5</td>\n",
       "      <td>78.26</td>\n",
       "      <td>0.661</td>\n",
       "      <td>14.2</td>\n",
       "      <td>12.565</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.0</td>\n",
       "      <td>79.05</td>\n",
       "      <td>0.658</td>\n",
       "      <td>14.8</td>\n",
       "      <td>13.050</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.5</td>\n",
       "      <td>86.10</td>\n",
       "      <td>0.655</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.115</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2795.0</td>\n",
       "      <td>74.58</td>\n",
       "      <td>0.647</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.300</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Facies Formation  Well Name   Depth     GR  ILD_log10  DeltaPHI   PHIND  \\\n",
       "0       3     A1 SH  SHRIMPLIN  2793.0  77.45      0.664       9.9  11.915   \n",
       "1       3     A1 SH  SHRIMPLIN  2793.5  78.26      0.661      14.2  12.565   \n",
       "2       3     A1 SH  SHRIMPLIN  2794.0  79.05      0.658      14.8  13.050   \n",
       "3       3     A1 SH  SHRIMPLIN  2794.5  86.10      0.655      13.9  13.115   \n",
       "4       3     A1 SH  SHRIMPLIN  2795.0  74.58      0.647      13.5  13.300   \n",
       "\n",
       "    PE  NM_M  RELPOS  \n",
       "0  4.6     1   1.000  \n",
       "1  4.1     1   0.979  \n",
       "2  3.6     1   0.957  \n",
       "3  3.5     1   0.936  \n",
       "4  3.4     1   0.915  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../facies_vectors.csv'\n",
    "training_data = pd.read_csv(filename)\n",
    "print(set(training_data[\"Well Name\"]))\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['CRAWFORD', 'STUART'])\n",
      "(830, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Formation</th>\n",
       "      <th>Well Name</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>66.276</td>\n",
       "      <td>0.630</td>\n",
       "      <td>3.3</td>\n",
       "      <td>10.65</td>\n",
       "      <td>3.591</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2808.5</td>\n",
       "      <td>77.252</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.5</td>\n",
       "      <td>11.95</td>\n",
       "      <td>3.341</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>82.899</td>\n",
       "      <td>0.566</td>\n",
       "      <td>9.4</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.064</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2809.5</td>\n",
       "      <td>80.671</td>\n",
       "      <td>0.593</td>\n",
       "      <td>9.5</td>\n",
       "      <td>13.25</td>\n",
       "      <td>2.977</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>75.971</td>\n",
       "      <td>0.638</td>\n",
       "      <td>8.7</td>\n",
       "      <td>12.35</td>\n",
       "      <td>3.020</td>\n",
       "      <td>1</td>\n",
       "      <td>0.911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Formation Well Name   Depth      GR  ILD_log10  DeltaPHI  PHIND     PE  \\\n",
       "0     A1 SH    STUART  2808.0  66.276      0.630       3.3  10.65  3.591   \n",
       "1     A1 SH    STUART  2808.5  77.252      0.585       6.5  11.95  3.341   \n",
       "2     A1 SH    STUART  2809.0  82.899      0.566       9.4  13.60  3.064   \n",
       "3     A1 SH    STUART  2809.5  80.671      0.593       9.5  13.25  2.977   \n",
       "4     A1 SH    STUART  2810.0  75.971      0.638       8.7  12.35  3.020   \n",
       "\n",
       "   NM_M  RELPOS  \n",
       "0     1   1.000  \n",
       "1     1   0.978  \n",
       "2     1   0.956  \n",
       "3     1   0.933  \n",
       "4     1   0.911  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "well_data = pd.read_csv('./../validation_data_nofacies.csv')\n",
    "print(set(well_data[\"Well Name\"]))\n",
    "print(well_data.shape)\n",
    "well_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Formation</th>\n",
       "      <th>Well Name</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>66.276</td>\n",
       "      <td>0.630</td>\n",
       "      <td>3.3</td>\n",
       "      <td>10.65</td>\n",
       "      <td>3.591</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2808.5</td>\n",
       "      <td>77.252</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.5</td>\n",
       "      <td>11.95</td>\n",
       "      <td>3.341</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>82.899</td>\n",
       "      <td>0.566</td>\n",
       "      <td>9.4</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.064</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2809.5</td>\n",
       "      <td>80.671</td>\n",
       "      <td>0.593</td>\n",
       "      <td>9.5</td>\n",
       "      <td>13.25</td>\n",
       "      <td>2.977</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>75.971</td>\n",
       "      <td>0.638</td>\n",
       "      <td>8.7</td>\n",
       "      <td>12.35</td>\n",
       "      <td>3.020</td>\n",
       "      <td>1</td>\n",
       "      <td>0.911</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2810.5</td>\n",
       "      <td>73.955</td>\n",
       "      <td>0.667</td>\n",
       "      <td>6.9</td>\n",
       "      <td>12.25</td>\n",
       "      <td>3.086</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2811.0</td>\n",
       "      <td>77.962</td>\n",
       "      <td>0.674</td>\n",
       "      <td>6.5</td>\n",
       "      <td>12.45</td>\n",
       "      <td>3.092</td>\n",
       "      <td>1</td>\n",
       "      <td>0.867</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2811.5</td>\n",
       "      <td>83.894</td>\n",
       "      <td>0.667</td>\n",
       "      <td>6.3</td>\n",
       "      <td>12.65</td>\n",
       "      <td>3.123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2812.0</td>\n",
       "      <td>84.424</td>\n",
       "      <td>0.653</td>\n",
       "      <td>6.7</td>\n",
       "      <td>13.05</td>\n",
       "      <td>3.121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.822</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2812.5</td>\n",
       "      <td>83.160</td>\n",
       "      <td>0.642</td>\n",
       "      <td>7.3</td>\n",
       "      <td>12.95</td>\n",
       "      <td>3.127</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Facies Formation Well Name   Depth      GR  ILD_log10  DeltaPHI  PHIND  \\\n",
       "0     NaN     A1 SH    STUART  2808.0  66.276      0.630       3.3  10.65   \n",
       "1     NaN     A1 SH    STUART  2808.5  77.252      0.585       6.5  11.95   \n",
       "2     NaN     A1 SH    STUART  2809.0  82.899      0.566       9.4  13.60   \n",
       "3     NaN     A1 SH    STUART  2809.5  80.671      0.593       9.5  13.25   \n",
       "4     NaN     A1 SH    STUART  2810.0  75.971      0.638       8.7  12.35   \n",
       "5     NaN     A1 SH    STUART  2810.5  73.955      0.667       6.9  12.25   \n",
       "6     NaN     A1 SH    STUART  2811.0  77.962      0.674       6.5  12.45   \n",
       "7     NaN     A1 SH    STUART  2811.5  83.894      0.667       6.3  12.65   \n",
       "8     NaN     A1 SH    STUART  2812.0  84.424      0.653       6.7  13.05   \n",
       "9     NaN     A1 SH    STUART  2812.5  83.160      0.642       7.3  12.95   \n",
       "\n",
       "      PE  NM_M  RELPOS origin  \n",
       "0  3.591     1   1.000   test  \n",
       "1  3.341     1   0.978   test  \n",
       "2  3.064     1   0.956   test  \n",
       "3  2.977     1   0.933   test  \n",
       "4  3.020     1   0.911   test  \n",
       "5  3.086     1   0.889   test  \n",
       "6  3.092     1   0.867   test  \n",
       "7  3.123     1   0.844   test  \n",
       "8  3.121     1   0.822   test  \n",
       "9  3.127     1   0.800   test  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat train and test for processing \n",
    "well_data[\"origin\"] = 'test'\n",
    "training_data[\"origin\"] = 'train'\n",
    "df = pd.concat([well_data,training_data],axis=0,ignore_index=True)[list(training_data.columns)]\n",
    "df['Well Name'] = df['Well Name'].astype('category')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session\n",
      "depth\n",
      "add avgs of feat\n",
      "add distances feat.\n",
      "lag lead\n",
      "rolling\n",
      "special window features for NM_M\n",
      "filling na\n",
      "Vectorizing Formation text data\n",
      "Finished preparing data. Now ready for ML ignition!\n"
     ]
    }
   ],
   "source": [
    "# add some features based on the well data. \n",
    "\n",
    "# nb points : can be correlated with how soft soil is ? \n",
    "print(\"session\")\n",
    "sessionsize = df.groupby([\"Well Name\",'Formation']).size().reset_index()\n",
    "sessionsize.columns =  [\"Well Name\",'Formation','formation_size']\n",
    "df = pd.merge(df,sessionsize,how='left',on = [\"Well Name\",'Formation'])\n",
    "\n",
    "# depth : \n",
    "print(\"depth\")\n",
    "sessionsize = df.groupby([\"Well Name\",'Formation'])[\"Depth\"].min().reset_index()\n",
    "sessionsize.columns =  [\"Well Name\",'Formation','minimum_depth']\n",
    "df = pd.merge(df,sessionsize,how='left',on = [\"Well Name\",'Formation'])\n",
    "\n",
    "sessionsize = df.groupby([\"Well Name\",'Formation'])[\"Depth\"].max().reset_index()\n",
    "sessionsize.columns =  [\"Well Name\",'Formation','maximum_depth']\n",
    "df = pd.merge(df,sessionsize,how='left',on = [\"Well Name\",'Formation'])\n",
    "\n",
    "df['formation_depth'] = df[\"maximum_depth\"] - df[\"minimum_depth\"]\n",
    "\n",
    "df[\"soft_indic\"] = df['formation_depth'] / df[\"formation_size\"]\n",
    "\n",
    "# add avgs of feat\n",
    "print(\"add avgs of feat\")\n",
    "list_to_avg = ['Depth', 'GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "for val in list_to_avg : \n",
    "    df[val + \"_min\"] = df.groupby([\"Well Name\",'Formation'])[val].transform(np.min)\n",
    "    df[val + \"_max\"] = df.groupby([\"Well Name\",'Formation'])[val].transform(np.max)\n",
    "    df[val + \"_mean\"] = df.groupby([\"Well Name\",'Formation'])[val].transform(np.mean)\n",
    "    df[val + \"_var\"] = df.groupby([\"Well Name\",'Formation'])[val].transform(np.var) \n",
    "\n",
    "# add distances feat. = an attempt at regulariation.\n",
    "print(\"add distances feat.\")\n",
    "for val in list_to_avg : \n",
    "    df[val + \"_min_dist\"] = df[val] -df[val + \"_min\"]\n",
    "    df[val + \"_max_dist\"] =  df[val] -df[val + \"_max\"]\n",
    "    df[val + \"_mean_dist\"] =  df[val] -df[val + \"_mean\"]\n",
    "    \n",
    "# add lag and lead !\n",
    "print(\"lag lead\")\n",
    "list_to_lag = ['Depth', 'GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "for val in list_to_lag:\n",
    "    for lag in range(1,11):\n",
    "        df[val+'_lag_'+str(lag)]=df[val]-df.groupby(\"Well Name\")[val].shift(periods=lag)\n",
    "        df[val+'_lead_'+str(lag)]=df[val]-df.groupby(\"Well Name\")[val].shift(periods=-lag)\n",
    "\n",
    "# adding some Formation lag and lead. \n",
    "for lag in range(1,3):\n",
    "    df['Formation'+'_lag_'+str(lag)]=df.groupby(\"Well Name\")['Formation'].shift(periods=lag)\n",
    "    df['Formation'+'_lead_'+str(lag)]=df.groupby(\"Well Name\")['Formation'].shift(periods=-lag)\n",
    "    df['Formation'+'_lag_'+str(lag) + 'equal'] = (df['Formation'+'_lag_'+str(lag)] == df[\"Formation\"]).astype(int)\n",
    "    df['Formation'+'_lead_'+str(lag) + 'equal'] = (df['Formation'+'_lead_'+str(lag)] == df[\"Formation\"]).astype(int) \n",
    "\n",
    "print(\"rolling\")\n",
    "#Add rolling features\n",
    "list_to_roll = ['Depth', 'GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M','RELPOS']\n",
    "window_size = [5,10,15,20,50]\n",
    "for w in window_size:\n",
    "    for val in list_to_roll:\n",
    "        df[val+'_rollingmean_'+str(w)]=df.groupby(\"Well Name\")[val].apply(\n",
    "            lambda x:x.rolling(window=w,center=True).mean())\n",
    "        df[val+'_rollingmax_'+str(w)]=df.groupby(\"Well Name\")[val].apply(\n",
    "            lambda x:x.rolling(window=w,center=True).max())\n",
    "        df[val+'_rollingmin_'+str(w)]=df.groupby(\"Well Name\")[val].apply(\n",
    "            lambda x:x.rolling(window=w,center=True).min())\n",
    "        df[val+'_rollingstd_'+str(w)]=df.groupby(\"Well Name\")[val].apply(\n",
    "            lambda x:x.rolling(window=w,center=True).std())\n",
    "        \n",
    "print(\"special window features for NM_M\")\n",
    "def NM_M_distance(x,how,target):\n",
    "    length = len(x)\n",
    "    rank = np.empty(length)\n",
    "    count = -1\n",
    "    NM_M = x[\"NM_M\"].values\n",
    "    if how==\"up\":\n",
    "        order = range(length)\n",
    "    elif how==\"down\":\n",
    "        order = range(length-1,-1,-1)\n",
    "    for i in order:\n",
    "        if ((NM_M[i] != target) & (count>-1)):\n",
    "            count+=1\n",
    "            rank[i] += count\n",
    "        elif NM_M[i] == target:\n",
    "            count=0\n",
    "        else:\n",
    "            rank[i] = count\n",
    "    rank = pd.DataFrame(rank.astype(int), columns=[\"NM_M_Rank_Target_+\"+str(target)+\"_\"+how], index = x.index)\n",
    "    return(rank)\n",
    "df[\"NM_M_Rank_Target_1_up\"]=df.groupby([\"Well Name\"]).apply(NM_M_distance,how=\"up\",target=1)\n",
    "df[\"NM_M_Rank_Target_2_up\"]=df.groupby([\"Well Name\"]).apply(NM_M_distance,how=\"up\",target=2)\n",
    "df[\"NM_M_Rank_Target_1_down\"]=df.groupby([\"Well Name\"]).apply(NM_M_distance,how=\"down\",target=1)\n",
    "df[\"NM_M_Rank_Target_2_down\"]=df.groupby([\"Well Name\"]).apply(NM_M_distance,how=\"down\",target=2)\n",
    "\n",
    "print(\"filling na\")\n",
    "df = df.groupby([\"Well Name\"], as_index=False).apply(lambda group: group.bfill())\n",
    "df = df.groupby([\"Well Name\"], as_index=False).apply(lambda group: group.ffill())\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "print(\"Vectorizing Formation text data\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "list_formation = ['Formation',\n",
    " 'Formation_lag_1',\n",
    " 'Formation_lead_1',\n",
    " 'Formation_lag_2',\n",
    " 'Formation_lead_2']\n",
    "for l in list_formation:\n",
    "    cv = CountVectorizer()\n",
    "    counts = cv.fit_transform(df[l].values)\n",
    "    cols = [c+\"_\"+l for c in cv.get_feature_names()]\n",
    "    counts = pd.DataFrame(counts.toarray(),columns = cols)\n",
    "    df = df.drop(l,axis = 1)\n",
    "    df = pd.concat([df,counts],axis=1)\n",
    "\n",
    "print(\"Finished preparing data. Now ready for ML ignition!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this time let's use all the training set \n",
    "groups = df[(df['origin']=='train')][\"Well Name\"]\n",
    "ytrain = df[(df['origin']=='train')]['Facies']\n",
    "yvalid = df[(df['origin']=='test')]['Facies']\n",
    "xtrain = df[(df['origin']=='train')].drop(['Well Name','origin','Facies'],axis=1)\n",
    "xvalid = df[(df['origin']=='test')].drop(['Well Name','origin','Facies'],axis=1)\n",
    "custom_cv = LeavePGroupsOut(n_groups=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4.5032537960954446}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(yvalid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_rfe = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion=\"entropy\",\n",
    "    class_weight='balanced',\n",
    "    min_samples_leaf=5,\n",
    "    min_samples_split=25,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 7 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFECV(cv=<generator object split at 0x10436eaf0>,\n",
       "   estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='entropy', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=5, min_samples_split=25,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "   n_jobs=4, scoring='f1_micro', step=0.1, verbose=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_cv_1 = custom_cv.split(xtrain, ytrain, groups)\n",
    "fs = RFECV(clf_rfe,cv=custom_cv_1,scoring=\"f1_micro\",step=0.1,verbose=2,n_jobs=4)\n",
    "fs.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n"
     ]
    }
   ],
   "source": [
    "support = fs.support_\n",
    "feature = pd.Series(xtrain.columns.values)\n",
    "selected_features = list(feature[support])\n",
    "print(len(selected_features))\n",
    "xtrain_fs = xtrain[selected_features].copy()\n",
    "xvalid_fs = xvalid[selected_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            criterion=\"entropy\",\n",
    "            class_weight='balanced',\n",
    "            min_samples_leaf=5,\n",
    "            min_samples_split=25,\n",
    "            max_features=10,\n",
    "            random_state=42\n",
    ")\n",
    "\n",
    "xtc =  ExtraTreesClassifier(\n",
    "            n_estimators=100,\n",
    "            criterion=\"entropy\",\n",
    "            class_weight='balanced',\n",
    "            min_samples_leaf=5,\n",
    "            min_samples_split=25,\n",
    "            max_features=10,\n",
    "            random_state=42\n",
    ")\n",
    "\n",
    "gbt = GradientBoostingClassifier(\n",
    "            loss='deviance',\n",
    "            n_estimators = 100, \n",
    "            learning_rate = 0.1, \n",
    "            max_depth = 3,\n",
    "            max_features = 10,\n",
    "            min_samples_leaf = 5,\n",
    "            min_samples_split = 25,\n",
    "            random_state = 42, \n",
    "            max_leaf_nodes = None\n",
    ")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "            learning_rate = 0.1, \n",
    "            max_depth = 3, \n",
    "            min_child_weight = 10, \n",
    "            n_estimators = 150, \n",
    "            colsample_bytree = 0.9,\n",
    "            seed = 42\n",
    ")\n",
    "\n",
    "custom_cv_2 = list(LeavePGroupsOut(n_groups=2).split(xtrain, ytrain, groups))\n",
    "stacked = StackedClassifier(clfs = [rf, xtc, gbt, xgb],\n",
    "                            level2_learner= LogisticRegression(),\n",
    "                            skf = custom_cv_2\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier [0]\n",
      "Fold [0]\n",
      "Fitting the model !\n",
      "accuracy_score on the 0-th fold: 0.549425287356\n",
      "Fold [1]\n",
      "Fitting the model !\n",
      "accuracy_score on the 1-th fold: 0.449844881075\n",
      "Fold [2]\n",
      "Fitting the model !\n",
      "accuracy_score on the 2-th fold: 0.53591160221\n",
      "Fold [3]\n",
      "Fitting the model !\n",
      "accuracy_score on the 3-th fold: 0.556634304207\n",
      "Fold [4]\n",
      "Fitting the model !\n",
      "accuracy_score on the 4-th fold: 0.482238966631\n",
      "Fold [5]\n",
      "Fitting the model !\n",
      "accuracy_score on the 5-th fold: 0.517593643587\n",
      "Fold [6]\n",
      "Fitting the model !\n",
      "accuracy_score on the 6-th fold: 0.567765567766\n",
      "Fold [7]\n",
      "Fitting the model !\n",
      "accuracy_score on the 7-th fold: 0.520218579235\n",
      "Fold [8]\n",
      "Fitting the model !\n",
      "accuracy_score on the 8-th fold: 0.590181430096\n",
      "Fold [9]\n",
      "Fitting the model !\n",
      "accuracy_score on the 9-th fold: 0.432044198895\n",
      "Fold [10]\n",
      "Fitting the model !\n",
      "accuracy_score on the 10-th fold: 0.571767497034\n",
      "Fold [11]\n",
      "Fitting the model !\n",
      "accuracy_score on the 11-th fold: 0.598843930636\n",
      "Fold [12]\n",
      "Fitting the model !\n",
      "accuracy_score on the 12-th fold: 0.491349480969\n",
      "Fold [13]\n",
      "Fitting the model !\n",
      "accuracy_score on the 13-th fold: 0.520146520147\n",
      "Fold [14]\n",
      "Fitting the model !\n",
      "accuracy_score on the 14-th fold: 0.407024793388\n",
      "Fold [15]\n",
      "Fitting the model !\n",
      "accuracy_score on the 15-th fold: 0.505275498242\n",
      "Fold [16]\n",
      "Fitting the model !\n",
      "accuracy_score on the 16-th fold: 0.582857142857\n",
      "Fold [17]\n",
      "Fitting the model !\n",
      "accuracy_score on the 17-th fold: 0.491489361702\n",
      "Fold [18]\n",
      "Fitting the model !\n",
      "accuracy_score on the 18-th fold: 0.597713097713\n",
      "Fold [19]\n",
      "Fitting the model !\n",
      "accuracy_score on the 19-th fold: 0.453319502075\n",
      "Fold [20]\n",
      "Fitting the model !\n",
      "accuracy_score on the 20-th fold: 0.445414847162\n",
      "Fold [21]\n",
      "Fitting the model !\n",
      "accuracy_score on the 21-th fold: 0.440619621343\n",
      "Fold [22]\n",
      "Fitting the model !\n",
      "accuracy_score on the 22-th fold: 0.368421052632\n",
      "Fold [23]\n",
      "Fitting the model !\n",
      "accuracy_score on the 23-th fold: 0.485596707819\n",
      "Fold [24]\n",
      "Fitting the model !\n",
      "accuracy_score on the 24-th fold: 0.597777777778\n",
      "Fold [25]\n",
      "Fitting the model !\n",
      "accuracy_score on the 25-th fold: 0.516629711752\n",
      "Fold [26]\n",
      "Fitting the model !\n",
      "accuracy_score on the 26-th fold: 0.538641686183\n",
      "Fold [27]\n",
      "Fitting the model !\n",
      "accuracy_score on the 27-th fold: 0.566473988439\n",
      "Fold [28]\n",
      "Fitting the model !\n",
      "accuracy_score on the 28-th fold: 0.522522522523\n",
      "Fold [29]\n",
      "Fitting the model !\n",
      "accuracy_score on the 29-th fold: 0.594505494505\n",
      "Fold [30]\n",
      "Fitting the model !\n",
      "accuracy_score on the 30-th fold: 0.559523809524\n",
      "Fold [31]\n",
      "Fitting the model !\n",
      "accuracy_score on the 31-th fold: 0.590182648402\n",
      "Fold [32]\n",
      "Fitting the model !\n",
      "accuracy_score on the 32-th fold: 0.624768946396\n",
      "Fold [33]\n",
      "Fitting the model !\n",
      "accuracy_score on the 33-th fold: 0.478021978022\n",
      "Fold [34]\n",
      "Fitting the model !\n",
      "accuracy_score on the 34-th fold: 0.596566523605\n",
      "Fold [35]\n",
      "Fitting the model !\n",
      "accuracy_score on the 35-th fold: 0.506833712984\n",
      "Fold [36]\n",
      "Fitting the model !\n",
      "accuracy_score on the 36-th fold: 0.521178637201\n",
      "Fold [37]\n",
      "Fitting the model !\n",
      "accuracy_score on the 37-th fold: 0.480263157895\n",
      "Fold [38]\n",
      "Fitting the model !\n",
      "accuracy_score on the 38-th fold: 0.581370449679\n",
      "Fold [39]\n",
      "Fitting the model !\n",
      "accuracy_score on the 39-th fold: 0.563636363636\n",
      "Fold [40]\n",
      "Fitting the model !\n",
      "accuracy_score on the 40-th fold: 0.523148148148\n",
      "Fold [41]\n",
      "Fitting the model !\n",
      "accuracy_score on the 41-th fold: 0.504514672686\n",
      "Fold [42]\n",
      "Fitting the model !\n",
      "accuracy_score on the 42-th fold: 0.523629489603\n",
      "Fold [43]\n",
      "Fitting the model !\n",
      "accuracy_score on the 43-th fold: 0.553539019964\n",
      "Fold [44]\n",
      "Fitting the model !\n",
      "accuracy_score on the 44-th fold: 0.486956521739\n",
      "Training classifier [1]\n",
      "Fold [0]\n",
      "Fitting the model !\n",
      "accuracy_score on the 0-th fold: 0.558620689655\n",
      "Fold [1]\n",
      "Fitting the model !\n",
      "accuracy_score on the 1-th fold: 0.481902792141\n",
      "Fold [2]\n",
      "Fitting the model !\n",
      "accuracy_score on the 2-th fold: 0.53591160221\n",
      "Fold [3]\n",
      "Fitting the model !\n",
      "accuracy_score on the 3-th fold: 0.517799352751\n",
      "Fold [4]\n",
      "Fitting the model !\n",
      "accuracy_score on the 4-th fold: 0.510226049516\n",
      "Fold [5]\n",
      "Fitting the model !\n",
      "accuracy_score on the 5-th fold: 0.530079455165\n",
      "Fold [6]\n",
      "Fitting the model !\n",
      "accuracy_score on the 6-th fold: 0.617216117216\n",
      "Fold [7]\n",
      "Fitting the model !\n",
      "accuracy_score on the 7-th fold: 0.502732240437\n",
      "Fold [8]\n",
      "Fitting the model !\n",
      "accuracy_score on the 8-th fold: 0.600853788687\n",
      "Fold [9]\n",
      "Fitting the model !\n",
      "accuracy_score on the 9-th fold: 0.459668508287\n",
      "Fold [10]\n",
      "Fitting the model !\n",
      "accuracy_score on the 10-th fold: 0.55871886121\n",
      "Fold [11]\n",
      "Fitting the model !\n",
      "accuracy_score on the 11-th fold: 0.524855491329\n",
      "Fold [12]\n",
      "Fitting the model !\n",
      "accuracy_score on the 12-th fold: 0.506343713956\n",
      "Fold [13]\n",
      "Fitting the model !\n",
      "accuracy_score on the 13-th fold: 0.527472527473\n",
      "Fold [14]\n",
      "Fitting the model !\n",
      "accuracy_score on the 14-th fold: 0.390495867769\n",
      "Fold [15]\n",
      "Fitting the model !\n",
      "accuracy_score on the 15-th fold: 0.511137162954\n",
      "Fold [16]\n",
      "Fitting the model !\n",
      "accuracy_score on the 16-th fold: 0.536\n",
      "Fold [17]\n",
      "Fitting the model !\n",
      "accuracy_score on the 17-th fold: 0.48829787234\n",
      "Fold [18]\n",
      "Fitting the model !\n",
      "accuracy_score on the 18-th fold: 0.607068607069\n",
      "Fold [19]\n",
      "Fitting the model !\n",
      "accuracy_score on the 19-th fold: 0.485477178423\n",
      "Fold [20]\n",
      "Fitting the model !\n",
      "accuracy_score on the 20-th fold: 0.485807860262\n",
      "Fold [21]\n",
      "Fitting the model !\n",
      "accuracy_score on the 21-th fold: 0.459552495697\n",
      "Fold [22]\n",
      "Fitting the model !\n",
      "accuracy_score on the 22-th fold: 0.334736842105\n",
      "Fold [23]\n",
      "Fitting the model !\n",
      "accuracy_score on the 23-th fold: 0.502057613169\n",
      "Fold [24]\n",
      "Fitting the model !\n",
      "accuracy_score on the 24-th fold: 0.526666666667\n",
      "Fold [25]\n",
      "Fitting the model !\n",
      "accuracy_score on the 25-th fold: 0.513303769401\n",
      "Fold [26]\n",
      "Fitting the model !\n",
      "accuracy_score on the 26-th fold: 0.555035128806\n",
      "Fold [27]\n",
      "Fitting the model !\n",
      "accuracy_score on the 27-th fold: 0.568400770713\n",
      "Fold [28]\n",
      "Fitting the model !\n",
      "accuracy_score on the 28-th fold: 0.484234234234\n",
      "Fold [29]\n",
      "Fitting the model !\n",
      "accuracy_score on the 29-th fold: 0.59010989011\n",
      "Fold [30]\n",
      "Fitting the model !\n",
      "accuracy_score on the 30-th fold: 0.489177489177\n",
      "Fold [31]\n",
      "Fitting the model !\n",
      "accuracy_score on the 31-th fold: 0.51598173516\n",
      "Fold [32]\n",
      "Fitting the model !\n",
      "accuracy_score on the 32-th fold: 0.543438077634\n",
      "Fold [33]\n",
      "Fitting the model !\n",
      "accuracy_score on the 33-th fold: 0.492307692308\n",
      "Fold [34]\n",
      "Fitting the model !\n",
      "accuracy_score on the 34-th fold: 0.507510729614\n",
      "Fold [35]\n",
      "Fitting the model !\n",
      "accuracy_score on the 35-th fold: 0.521640091116\n",
      "Fold [36]\n",
      "Fitting the model !\n",
      "accuracy_score on the 36-th fold: 0.515653775322\n",
      "Fold [37]\n",
      "Fitting the model !\n",
      "accuracy_score on the 37-th fold: 0.468201754386\n",
      "Fold [38]\n",
      "Fitting the model !\n",
      "accuracy_score on the 38-th fold: 0.601713062099\n",
      "Fold [39]\n",
      "Fitting the model !\n",
      "accuracy_score on the 39-th fold: 0.569696969697\n",
      "Fold [40]\n",
      "Fitting the model !\n",
      "accuracy_score on the 40-th fold: 0.52662037037\n",
      "Fold [41]\n",
      "Fitting the model !\n",
      "accuracy_score on the 41-th fold: 0.51467268623\n",
      "Fold [42]\n",
      "Fitting the model !\n",
      "accuracy_score on the 42-th fold: 0.491493383743\n",
      "Fold [43]\n",
      "Fitting the model !\n",
      "accuracy_score on the 43-th fold: 0.620689655172\n",
      "Fold [44]\n",
      "Fitting the model !\n",
      "accuracy_score on the 44-th fold: 0.515217391304\n",
      "Training classifier [2]\n",
      "Fold [0]\n",
      "Fitting the model !\n",
      "accuracy_score on the 0-th fold: 0.54367816092\n",
      "Fold [1]\n",
      "Fitting the model !\n",
      "accuracy_score on the 1-th fold: 0.486039296794\n",
      "Fold [2]\n",
      "Fitting the model !\n",
      "accuracy_score on the 2-th fold: 0.570165745856\n",
      "Fold [3]\n",
      "Fitting the model !\n",
      "accuracy_score on the 3-th fold: 0.615965480043\n",
      "Fold [4]\n",
      "Fitting the model !\n",
      "accuracy_score on the 4-th fold: 0.539289558665\n",
      "Fold [5]\n",
      "Fitting the model !\n",
      "accuracy_score on the 5-th fold: 0.564131668558\n",
      "Fold [6]\n",
      "Fitting the model !\n",
      "accuracy_score on the 6-th fold: 0.615384615385\n",
      "Fold [7]\n",
      "Fitting the model !\n",
      "accuracy_score on the 7-th fold: 0.591256830601\n",
      "Fold [8]\n",
      "Fitting the model !\n",
      "accuracy_score on the 8-th fold: 0.616862326574\n",
      "Fold [9]\n",
      "Fitting the model !\n",
      "accuracy_score on the 9-th fold: 0.394475138122\n",
      "Fold [10]\n",
      "Fitting the model !\n",
      "accuracy_score on the 10-th fold: 0.511269276394\n",
      "Fold [11]\n",
      "Fitting the model !\n",
      "accuracy_score on the 11-th fold: 0.543352601156\n",
      "Fold [12]\n",
      "Fitting the model !\n",
      "accuracy_score on the 12-th fold: 0.495963091119\n",
      "Fold [13]\n",
      "Fitting the model !\n",
      "accuracy_score on the 13-th fold: 0.547008547009\n",
      "Fold [14]\n",
      "Fitting the model !\n",
      "accuracy_score on the 14-th fold: 0.371900826446\n",
      "Fold [15]\n",
      "Fitting the model !\n",
      "accuracy_score on the 15-th fold: 0.539273153576\n",
      "Fold [16]\n",
      "Fitting the model !\n",
      "accuracy_score on the 16-th fold: 0.516571428571\n",
      "Fold [17]\n",
      "Fitting the model !\n",
      "accuracy_score on the 17-th fold: 0.423404255319\n",
      "Fold [18]\n",
      "Fitting the model !\n",
      "accuracy_score on the 18-th fold: 0.5841995842\n",
      "Fold [19]\n",
      "Fitting the model !\n",
      "accuracy_score on the 19-th fold: 0.427385892116\n",
      "Fold [20]\n",
      "Fitting the model !\n",
      "accuracy_score on the 20-th fold: 0.446506550218\n",
      "Fold [21]\n",
      "Fitting the model !\n",
      "accuracy_score on the 21-th fold: 0.36660929432\n",
      "Fold [22]\n",
      "Fitting the model !\n",
      "accuracy_score on the 22-th fold: 0.350526315789\n",
      "Fold [23]\n",
      "Fitting the model !\n",
      "accuracy_score on the 23-th fold: 0.475308641975\n",
      "Fold [24]\n",
      "Fitting the model !\n",
      "accuracy_score on the 24-th fold: 0.581111111111\n",
      "Fold [25]\n",
      "Fitting the model !\n",
      "accuracy_score on the 25-th fold: 0.49889135255\n",
      "Fold [26]\n",
      "Fitting the model !\n",
      "accuracy_score on the 26-th fold: 0.550351288056\n",
      "Fold [27]\n",
      "Fitting the model !\n",
      "accuracy_score on the 27-th fold: 0.522157996146\n",
      "Fold [28]\n",
      "Fitting the model !\n",
      "accuracy_score on the 28-th fold: 0.523648648649\n",
      "Fold [29]\n",
      "Fitting the model !\n",
      "accuracy_score on the 29-th fold: 0.582417582418\n",
      "Fold [30]\n",
      "Fitting the model !\n",
      "accuracy_score on the 30-th fold: 0.504329004329\n",
      "Fold [31]\n",
      "Fitting the model !\n",
      "accuracy_score on the 31-th fold: 0.584474885845\n",
      "Fold [32]\n",
      "Fitting the model !\n",
      "accuracy_score on the 32-th fold: 0.608133086876\n",
      "Fold [33]\n",
      "Fitting the model !\n",
      "accuracy_score on the 33-th fold: 0.57032967033\n",
      "Fold [34]\n",
      "Fitting the model !\n",
      "accuracy_score on the 34-th fold: 0.582618025751\n",
      "Fold [35]\n",
      "Fitting the model !\n",
      "accuracy_score on the 35-th fold: 0.514806378132\n",
      "Fold [36]\n",
      "Fitting the model !\n",
      "accuracy_score on the 36-th fold: 0.51197053407\n",
      "Fold [37]\n",
      "Fitting the model !\n",
      "accuracy_score on the 37-th fold: 0.536184210526\n",
      "Fold [38]\n",
      "Fitting the model !\n",
      "accuracy_score on the 38-th fold: 0.597430406852\n",
      "Fold [39]\n",
      "Fitting the model !\n",
      "accuracy_score on the 39-th fold: 0.579797979798\n",
      "Fold [40]\n",
      "Fitting the model !\n",
      "accuracy_score on the 40-th fold: 0.570601851852\n",
      "Fold [41]\n",
      "Fitting the model !\n",
      "accuracy_score on the 41-th fold: 0.540632054176\n",
      "Fold [42]\n",
      "Fitting the model !\n",
      "accuracy_score on the 42-th fold: 0.603024574669\n",
      "Fold [43]\n",
      "Fitting the model !\n",
      "accuracy_score on the 43-th fold: 0.569872958258\n",
      "Fold [44]\n",
      "Fitting the model !\n",
      "accuracy_score on the 44-th fold: 0.565217391304\n",
      "Training classifier [3]\n",
      "Fold [0]\n",
      "Fitting the model !\n",
      "accuracy_score on the 0-th fold: 0.56091954023\n",
      "Fold [1]\n",
      "Fitting the model !\n",
      "accuracy_score on the 1-th fold: 0.506721820062\n",
      "Fold [2]\n",
      "Fitting the model !\n",
      "accuracy_score on the 2-th fold: 0.572375690608\n",
      "Fold [3]\n",
      "Fitting the model !\n",
      "accuracy_score on the 3-th fold: 0.607335490831\n",
      "Fold [4]\n",
      "Fitting the model !\n",
      "accuracy_score on the 4-th fold: 0.539289558665\n",
      "Fold [5]\n",
      "Fitting the model !\n",
      "accuracy_score on the 5-th fold: 0.5561861521\n",
      "Fold [6]\n",
      "Fitting the model !\n",
      "accuracy_score on the 6-th fold: 0.635531135531\n",
      "Fold [7]\n",
      "Fitting the model !\n",
      "accuracy_score on the 7-th fold: 0.609836065574\n",
      "Fold [8]\n",
      "Fitting the model !\n",
      "accuracy_score on the 8-th fold: 0.581643543223\n",
      "Fold [9]\n",
      "Fitting the model !\n",
      "accuracy_score on the 9-th fold: 0.420994475138\n",
      "Fold [10]\n",
      "Fitting the model !\n",
      "accuracy_score on the 10-th fold: 0.506524317912\n",
      "Fold [11]\n",
      "Fitting the model !\n",
      "accuracy_score on the 11-th fold: 0.575722543353\n",
      "Fold [12]\n",
      "Fitting the model !\n",
      "accuracy_score on the 12-th fold: 0.528258362168\n",
      "Fold [13]\n",
      "Fitting the model !\n",
      "accuracy_score on the 13-th fold: 0.529914529915\n",
      "Fold [14]\n",
      "Fitting the model !\n",
      "accuracy_score on the 14-th fold: 0.394628099174\n",
      "Fold [15]\n",
      "Fitting the model !\n",
      "accuracy_score on the 15-th fold: 0.57796014068\n",
      "Fold [16]\n",
      "Fitting the model !\n",
      "accuracy_score on the 16-th fold: 0.540571428571\n",
      "Fold [17]\n",
      "Fitting the model !\n",
      "accuracy_score on the 17-th fold: 0.470212765957\n",
      "Fold [18]\n",
      "Fitting the model !\n",
      "accuracy_score on the 18-th fold: 0.546777546778\n",
      "Fold [19]\n",
      "Fitting the model !\n",
      "accuracy_score on the 19-th fold: 0.438796680498\n",
      "Fold [20]\n",
      "Fitting the model !\n",
      "accuracy_score on the 20-th fold: 0.454148471616\n",
      "Fold [21]\n",
      "Fitting the model !\n",
      "accuracy_score on the 21-th fold: 0.421686746988\n",
      "Fold [22]\n",
      "Fitting the model !\n",
      "accuracy_score on the 22-th fold: 0.349473684211\n",
      "Fold [23]\n",
      "Fitting the model !\n",
      "accuracy_score on the 23-th fold: 0.491769547325\n",
      "Fold [24]\n",
      "Fitting the model !\n",
      "accuracy_score on the 24-th fold: 0.543333333333\n",
      "Fold [25]\n",
      "Fitting the model !\n",
      "accuracy_score on the 25-th fold: 0.519955654102\n",
      "Fold [26]\n",
      "Fitting the model !\n",
      "accuracy_score on the 26-th fold: 0.531615925059\n",
      "Fold [27]\n",
      "Fitting the model !\n",
      "accuracy_score on the 27-th fold: 0.543352601156\n",
      "Fold [28]\n",
      "Fitting the model !\n",
      "accuracy_score on the 28-th fold: 0.560810810811\n",
      "Fold [29]\n",
      "Fitting the model !\n",
      "accuracy_score on the 29-th fold: 0.543956043956\n",
      "Fold [30]\n",
      "Fitting the model !\n",
      "accuracy_score on the 30-th fold: 0.522727272727\n",
      "Fold [31]\n",
      "Fitting the model !\n",
      "accuracy_score on the 31-th fold: 0.5399543379\n",
      "Fold [32]\n",
      "Fitting the model !\n",
      "accuracy_score on the 32-th fold: 0.619223659889\n",
      "Fold [33]\n",
      "Fitting the model !\n",
      "accuracy_score on the 33-th fold: 0.540659340659\n",
      "Fold [34]\n",
      "Fitting the model !\n",
      "accuracy_score on the 34-th fold: 0.554721030043\n",
      "Fold [35]\n",
      "Fitting the model !\n",
      "accuracy_score on the 35-th fold: 0.53416856492\n",
      "Fold [36]\n",
      "Fitting the model !\n",
      "accuracy_score on the 36-th fold: 0.469613259669\n",
      "Fold [37]\n",
      "Fitting the model !\n",
      "accuracy_score on the 37-th fold: 0.571271929825\n",
      "Fold [38]\n",
      "Fitting the model !\n",
      "accuracy_score on the 38-th fold: 0.571734475375\n",
      "Fold [39]\n",
      "Fitting the model !\n",
      "accuracy_score on the 39-th fold: 0.527272727273\n",
      "Fold [40]\n",
      "Fitting the model !\n",
      "accuracy_score on the 40-th fold: 0.542824074074\n",
      "Fold [41]\n",
      "Fitting the model !\n",
      "accuracy_score on the 41-th fold: 0.511286681716\n",
      "Fold [42]\n",
      "Fitting the model !\n",
      "accuracy_score on the 42-th fold: 0.631379962193\n",
      "Fold [43]\n",
      "Fitting the model !\n",
      "accuracy_score on the 43-th fold: 0.551724137931\n",
      "Fold [44]\n",
      "Fitting the model !\n",
      "accuracy_score on the 44-th fold: 0.579347826087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackedClassifier(clfs=[RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='entropy', max_depth=None, max_features=10,\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=5, min_samples_split=25,\n",
       "            min_weight_fraction_leaf=0.0, n_estimat...logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=42, silent=True, subsample=1)],\n",
       "         level2_learner=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "         oob_metrics=<function accuracy_score at 0x114abc2a8>,\n",
       "         save_dir=None,\n",
       "         skf=[(array([   0,    1, ..., 3743, 3744]), array([ 471,  472, ..., 4147, 4148])), (array([   0,    1, ..., 4147, 4148]), array([ 471,  472, ..., 2785, 2786])), (array([   0,    1, ..., 4147, 4148]), array([ 471,  472, ..., 2284, 2285])), (array([   0,    1, ..., 4147, 4148]), array([ 471,  472, ......1, ..., 3280, 3281])), (array([ 471,  472, ..., 4147, 4148]), array([   0,    1, ..., 1384, 1385]))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.fit(xtrain_fs.values, ytrain.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "well_name_valid = df.loc[(df['origin']=='test'),\"Well Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training classifier [0] ...\n",
      "... of Fold [0]\n",
      "... of Fold [1]\n",
      "... of Fold [2]\n",
      "... of Fold [3]\n",
      "... of Fold [4]\n",
      "... of Fold [5]\n",
      "... of Fold [6]\n",
      "... of Fold [7]\n",
      "... of Fold [8]\n",
      "... of Fold [9]\n",
      "... of Fold [10]\n",
      "... of Fold [11]\n",
      "... of Fold [12]\n",
      "... of Fold [13]\n",
      "... of Fold [14]\n",
      "... of Fold [15]\n",
      "... of Fold [16]\n",
      "... of Fold [17]\n",
      "... of Fold [18]\n",
      "... of Fold [19]\n",
      "... of Fold [20]\n",
      "... of Fold [21]\n",
      "... of Fold [22]\n",
      "... of Fold [23]\n",
      "... of Fold [24]\n",
      "... of Fold [25]\n",
      "... of Fold [26]\n",
      "... of Fold [27]\n",
      "... of Fold [28]\n",
      "... of Fold [29]\n",
      "... of Fold [30]\n",
      "... of Fold [31]\n",
      "... of Fold [32]\n",
      "... of Fold [33]\n",
      "... of Fold [34]\n",
      "... of Fold [35]\n",
      "... of Fold [36]\n",
      "... of Fold [37]\n",
      "... of Fold [38]\n",
      "... of Fold [39]\n",
      "... of Fold [40]\n",
      "... of Fold [41]\n",
      "... of Fold [42]\n",
      "... of Fold [43]\n",
      "... of Fold [44]\n",
      "Loading Training classifier [1] ...\n",
      "... of Fold [0]\n",
      "... of Fold [1]\n",
      "... of Fold [2]\n",
      "... of Fold [3]\n",
      "... of Fold [4]\n",
      "... of Fold [5]\n",
      "... of Fold [6]\n",
      "... of Fold [7]\n",
      "... of Fold [8]\n",
      "... of Fold [9]\n",
      "... of Fold [10]\n",
      "... of Fold [11]\n",
      "... of Fold [12]\n",
      "... of Fold [13]\n",
      "... of Fold [14]\n",
      "... of Fold [15]\n",
      "... of Fold [16]\n",
      "... of Fold [17]\n",
      "... of Fold [18]\n",
      "... of Fold [19]\n",
      "... of Fold [20]\n",
      "... of Fold [21]\n",
      "... of Fold [22]\n",
      "... of Fold [23]\n",
      "... of Fold [24]\n",
      "... of Fold [25]\n",
      "... of Fold [26]\n",
      "... of Fold [27]\n",
      "... of Fold [28]\n",
      "... of Fold [29]\n",
      "... of Fold [30]\n",
      "... of Fold [31]\n",
      "... of Fold [32]\n",
      "... of Fold [33]\n",
      "... of Fold [34]\n",
      "... of Fold [35]\n",
      "... of Fold [36]\n",
      "... of Fold [37]\n",
      "... of Fold [38]\n",
      "... of Fold [39]\n",
      "... of Fold [40]\n",
      "... of Fold [41]\n",
      "... of Fold [42]\n",
      "... of Fold [43]\n",
      "... of Fold [44]\n",
      "Loading Training classifier [2] ...\n",
      "... of Fold [0]\n",
      "... of Fold [1]\n",
      "... of Fold [2]\n",
      "... of Fold [3]\n",
      "... of Fold [4]\n",
      "... of Fold [5]\n",
      "... of Fold [6]\n",
      "... of Fold [7]\n",
      "... of Fold [8]\n",
      "... of Fold [9]\n",
      "... of Fold [10]\n",
      "... of Fold [11]\n",
      "... of Fold [12]\n",
      "... of Fold [13]\n",
      "... of Fold [14]\n",
      "... of Fold [15]\n",
      "... of Fold [16]\n",
      "... of Fold [17]\n",
      "... of Fold [18]\n",
      "... of Fold [19]\n",
      "... of Fold [20]\n",
      "... of Fold [21]\n",
      "... of Fold [22]\n",
      "... of Fold [23]\n",
      "... of Fold [24]\n",
      "... of Fold [25]\n",
      "... of Fold [26]\n",
      "... of Fold [27]\n",
      "... of Fold [28]\n",
      "... of Fold [29]\n",
      "... of Fold [30]\n",
      "... of Fold [31]\n",
      "... of Fold [32]\n",
      "... of Fold [33]\n",
      "... of Fold [34]\n",
      "... of Fold [35]\n",
      "... of Fold [36]\n",
      "... of Fold [37]\n",
      "... of Fold [38]\n",
      "... of Fold [39]\n",
      "... of Fold [40]\n",
      "... of Fold [41]\n",
      "... of Fold [42]\n",
      "... of Fold [43]\n",
      "... of Fold [44]\n",
      "Loading Training classifier [3] ...\n",
      "... of Fold [0]\n",
      "... of Fold [1]\n",
      "... of Fold [2]\n",
      "... of Fold [3]\n",
      "... of Fold [4]\n",
      "... of Fold [5]\n",
      "... of Fold [6]\n",
      "... of Fold [7]\n",
      "... of Fold [8]\n",
      "... of Fold [9]\n",
      "... of Fold [10]\n",
      "... of Fold [11]\n",
      "... of Fold [12]\n",
      "... of Fold [13]\n",
      "... of Fold [14]\n",
      "... of Fold [15]\n",
      "... of Fold [16]\n",
      "... of Fold [17]\n",
      "... of Fold [18]\n",
      "... of Fold [19]\n",
      "... of Fold [20]\n",
      "... of Fold [21]\n",
      "... of Fold [22]\n",
      "... of Fold [23]\n",
      "... of Fold [24]\n",
      "... of Fold [25]\n",
      "... of Fold [26]\n",
      "... of Fold [27]\n",
      "... of Fold [28]\n",
      "... of Fold [29]\n",
      "... of Fold [30]\n",
      "... of Fold [31]\n",
      "... of Fold [32]\n",
      "... of Fold [33]\n",
      "... of Fold [34]\n",
      "... of Fold [35]\n",
      "... of Fold [36]\n",
      "... of Fold [37]\n",
      "... of Fold [38]\n",
      "... of Fold [39]\n",
      "... of Fold [40]\n",
      "... of Fold [41]\n",
      "... of Fold [42]\n",
      "... of Fold [43]\n",
      "... of Fold [44]\n"
     ]
    }
   ],
   "source": [
    "preds = stacked.predict_proba(xvalid_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = list(set(ytrain))\n",
    "preds_hard = [classes[i] for i in np.argmax(preds, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAFkCAYAAADSRRn0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxP8DIFNCiqIp89wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x159db75d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "well = \"CRAWFORD\"\n",
    "depth = xvalid.loc[well_name_valid== well ,\"Depth\"]\n",
    "predictions = pd.Series(preds_hard).loc[well_name_valid==well]\n",
    "plt.plot(depth,predictions)\n",
    "plt.axis([2950,3175, 1, 9])\n",
    "plt.grid(b=True, which='major', color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAFkCAYAAABFIsPfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbfx/9q4PRa34AqgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x159dbec90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "well = \"STUART\"\n",
    "depth = xvalid.loc[well_name_valid== well ,\"Depth\"]\n",
    "predictions = pd.Series(preds_hard).loc[well_name_valid==well]\n",
    "plt.plot(depth,predictions)\n",
    "plt.axis([2800,3050, 1, 9])\n",
    "plt.grid(b=True, which='major', color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xvalid['Facies']=preds_hard\n",
    "xvalid.to_csv('XmasPreds_6.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
