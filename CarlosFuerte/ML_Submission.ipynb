{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Contest\n",
    "By: Kris Darnell & David Tang\n",
    "\n",
    "Test run with a larger sized neural network. Contest is described [here](https://github.com/seg/2016-ml-contest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.503254</td>\n",
       "      <td>2906.867438</td>\n",
       "      <td>64.933985</td>\n",
       "      <td>0.659566</td>\n",
       "      <td>4.402484</td>\n",
       "      <td>13.201066</td>\n",
       "      <td>3.725014</td>\n",
       "      <td>1.518438</td>\n",
       "      <td>0.521852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.474324</td>\n",
       "      <td>133.300164</td>\n",
       "      <td>30.302530</td>\n",
       "      <td>0.252703</td>\n",
       "      <td>5.274947</td>\n",
       "      <td>7.132846</td>\n",
       "      <td>0.790917</td>\n",
       "      <td>0.499720</td>\n",
       "      <td>0.286644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2573.500000</td>\n",
       "      <td>10.149000</td>\n",
       "      <td>-0.025949</td>\n",
       "      <td>-21.832000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2821.500000</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>0.498000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.277000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2932.500000</td>\n",
       "      <td>64.990000</td>\n",
       "      <td>0.639000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>3.725014</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>3007.000000</td>\n",
       "      <td>79.438000</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>16.050000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.769000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3138.000000</td>\n",
       "      <td>361.150000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>19.312000</td>\n",
       "      <td>84.400000</td>\n",
       "      <td>8.094000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Facies        Depth           GR    ILD_log10     DeltaPHI  \\\n",
       "count  4149.000000  4149.000000  4149.000000  4149.000000  4149.000000   \n",
       "mean      4.503254  2906.867438    64.933985     0.659566     4.402484   \n",
       "std       2.474324   133.300164    30.302530     0.252703     5.274947   \n",
       "min       1.000000  2573.500000    10.149000    -0.025949   -21.832000   \n",
       "25%       2.000000  2821.500000    44.730000     0.498000     1.600000   \n",
       "50%       4.000000  2932.500000    64.990000     0.639000     4.300000   \n",
       "75%       6.000000  3007.000000    79.438000     0.822000     7.500000   \n",
       "max       9.000000  3138.000000   361.150000     1.800000    19.312000   \n",
       "\n",
       "             PHIND           PE         NM_M       RELPOS  \n",
       "count  4149.000000  4149.000000  4149.000000  4149.000000  \n",
       "mean     13.201066     3.725014     1.518438     0.521852  \n",
       "std       7.132846     0.790917     0.499720     0.286644  \n",
       "min       0.550000     0.200000     1.000000     0.000000  \n",
       "25%       8.500000     3.200000     1.000000     0.277000  \n",
       "50%      12.020000     3.725014     2.000000     0.528000  \n",
       "75%      16.050000     4.000000     2.000000     0.769000  \n",
       "max      84.400000     8.094000     2.000000     1.000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from pandas import set_option\n",
    "set_option(\"display.max_rows\", 10)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Loading Data\n",
    "filename = 'facies_vectors.csv'                         # Read in training data\n",
    "training_data = pd.read_csv(filename)\n",
    "training_data.fillna(training_data.mean(),inplace=True) # Remove NaN with mean value\n",
    "training_data\n",
    "filename = 'validation_data_nofacies.csv'               # Read in test well\n",
    "validationFull = pd.read_csv(filename)\n",
    "\n",
    "# Converts to category\n",
    "training_data['Well Name'] = training_data['Well Name'].astype('category')\n",
    "training_data['Formation'] = training_data['Formation'].astype('category')\n",
    "training_data['Well Name'].unique()\n",
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00',\n",
    "       '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "\n",
    "facies_labels = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS',\n",
    "                 'WS', 'D','PS', 'BS']\n",
    "#facies_color_map is a dictionary that maps facies labels\n",
    "#to their respective colors\n",
    "facies_color_map = {}   # Dictionary # enumerate puts out ind=0, label=SS, and loops through the whole thing\n",
    "for ind, label in enumerate(facies_labels):\n",
    "    facies_color_map[label] = facies_colors[ind]\n",
    "   \n",
    "def label_facies(row, labels):\n",
    "    return labels[ row['Facies'] -1]\n",
    "    \n",
    "training_data.loc[:,'FaciesLabels'] = training_data.apply(lambda row: label_facies(row, facies_labels), axis=1)\n",
    "\n",
    "correct_facies_labels = training_data['Facies'].values\n",
    "\n",
    "feature_vectors = training_data.drop(['Well Name','Facies','FaciesLabels'], axis=1)\n",
    "\n",
    "feature_vectors.describe()\n",
    "\n",
    "feature_vectors.insert(1,'FormationNum',0)\n",
    "validationFull.insert(1,'FormationNum',0)\n",
    "\n",
    "for ii, formation in enumerate(feature_vectors['Formation'].unique()):\n",
    "    feature_vectors.FormationNum[feature_vectors.Formation == formation] = ii\n",
    "    validationFull.FormationNum[validationFull.Formation == formation] = ii\n",
    "    \n",
    "feature_vectors = feature_vectors.drop(['Formation'], axis = 1)\n",
    "validation = validationFull.drop(['Formation', 'Well Name'], axis = 1)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Normalizing and splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_safe_split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-528f8f7500fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtpot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTPOTClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_union\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dgt377/anaconda/lib/python3.5/site-packages/sklearn/model_selection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlearning_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dgt377/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_is_arraylike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetaestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_safe_split'"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tpot import TPOTClassifier \n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(feature_vectors)\n",
    "scaled_features = scaler.transform(feature_vectors)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        scaled_features, correct_facies_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use extra trees\n",
    "clfExtra = make_pipeline(\n",
    "    ExtraTreesClassifier(criterion=\"gini\", max_features=0.53, n_estimators=500))\n",
    "clfExtra.fit(X_train, y_train)\n",
    "\n",
    "predicted = clfExtra.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from classification_utilities import display_cm, display_adj_cm\n",
    "\n",
    "conf_NN  = confusion_matrix(y_test,predicted_NN)\n",
    "conf_One = confusion_matrix(y_test,predicted_One) \n",
    "display_cm(conf_NN,facies_labels,hide_zeros=True)\n",
    "\n",
    "\n",
    "def accuracy(conf):\n",
    "    total_correct = 0.\n",
    "    nb_classes = conf.shape[0]\n",
    "    for i in np.arange(0,nb_classes):\n",
    "        total_correct += conf[i][i]\n",
    "    acc = total_correct/sum(sum(conf))\n",
    "    return acc\n",
    "\n",
    "\n",
    "adjacent_facies = np.array([[1], [0,2], [1], [4], [3,5], [4,6,7], [5,7], [5,6,8], [6,7]])\n",
    "\n",
    "def accuracy_adjacent(conf, adjacent_facies):\n",
    "    nb_classes = conf.shape[0]\n",
    "    total_correct = 0.\n",
    "    for i in np.arange(0,nb_classes):\n",
    "        total_correct += conf[i][i]\n",
    "        for j in adjacent_facies[i]:\n",
    "            total_correct += conf[i][j]\n",
    "    return total_correct / sum(sum(conf))\n",
    "\n",
    "print('Facies classification accuracy (NN) = %f' % accuracy(conf_NN))\n",
    "print('Facies classification accuracy (OneVsRest) = %f' % accuracy(conf_One))\n",
    "print('Adjacent facies classification accuracy (NN) = %f' % accuracy_adjacent(conf_NN, adjacent_facies))\n",
    "print('Adjacent facies classification accuracy (OneVsRest) = %f' % accuracy_adjacent(conf_One, adjacent_facies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain using the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrain on all data\n",
    "clfExtra.fit(scaled_features, correct_facies_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to test well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "scaled_validation = scaler.transform(validation)\n",
    "validation_output = clfExtra.predict(scaled_validation)\n",
    "\n",
    "from scipy.signal import medfilt\n",
    "# Smooth data\n",
    "validation_output = medfilt(validation_output,kernel_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_facies_log_plot(logs, facies_colors):\n",
    "   #make sure logs are sorted by depth\n",
    "   logs = logs.sort_values(by='Depth')\n",
    "   cmap_facies = colors.ListedColormap(\n",
    "           facies_colors[0:len(facies_colors)], 'indexed')\n",
    "   \n",
    "   ztop=logs.Depth.min(); zbot=logs.Depth.max()\n",
    "   \n",
    "   cluster=np.repeat(np.expand_dims(logs['Facies'].values,1), 100, 1) # Makes it a nx1, repeating values along an dimension\n",
    "   \n",
    "   f, ax = plt.subplots(nrows=1, ncols=6, figsize=(8, 12))\n",
    "   ax[0].plot(logs.GR, logs.Depth, '-g')\n",
    "   ax[1].plot(logs.ILD_log10, logs.Depth, '-')\n",
    "   ax[2].plot(logs.DeltaPHI, logs.Depth, '-', color='0.5')\n",
    "   ax[3].plot(logs.PHIND, logs.Depth, '-', color='r')\n",
    "   ax[4].plot(logs.PE, logs.Depth, '-', color='black')\n",
    "   im=ax[5].imshow(cluster, interpolation='none', aspect='auto',\n",
    "                   cmap=cmap_facies,vmin=1,vmax=9)\n",
    "   \n",
    "   divider = make_axes_locatable(ax[5])\n",
    "   cax = divider.append_axes(\"right\", size=\"20%\", pad=0.05)\n",
    "   cbar=plt.colorbar(im, cax=cax)\n",
    "   cbar.set_label((17*' ').join([' SS ', 'CSiS', 'FSiS', \n",
    "                               'SiSh', ' MS ', ' WS ', ' D  ', \n",
    "                               ' PS ', ' BS ']))\n",
    "   cbar.set_ticks(range(0,1)); cbar.set_ticklabels('')\n",
    "   \n",
    "   for i in range(len(ax)-1):\n",
    "       ax[i].set_ylim(ztop,zbot)\n",
    "       ax[i].invert_yaxis()\n",
    "       ax[i].grid()\n",
    "       ax[i].locator_params(axis='x', nbins=3)\n",
    "   \n",
    "   ax[0].set_xlabel(\"GR\")\n",
    "   ax[0].set_xlim(logs.GR.min(),logs.GR.max())\n",
    "   ax[1].set_xlabel(\"ILD_log10\")\n",
    "   ax[1].set_xlim(logs.ILD_log10.min(),logs.ILD_log10.max())\n",
    "   ax[2].set_xlabel(\"DeltaPHI\")\n",
    "   ax[2].set_xlim(logs.DeltaPHI.min(),logs.DeltaPHI.max())\n",
    "   ax[3].set_xlabel(\"PHIND\")\n",
    "   ax[3].set_xlim(logs.PHIND.min(),logs.PHIND.max())\n",
    "   ax[4].set_xlabel(\"PE\")\n",
    "   ax[4].set_xlim(logs.PE.min(),logs.PE.max())\n",
    "   ax[5].set_xlabel('Facies')\n",
    "   \n",
    "   ax[1].set_yticklabels([]); ax[2].set_yticklabels([]); ax[3].set_yticklabels([])\n",
    "   ax[4].set_yticklabels([]); ax[5].set_yticklabels([])\n",
    "   ax[5].set_xticklabels([])\n",
    "   f.suptitle('Well: %s'%logs.iloc[0]['Well Name'], fontsize=14,y=0.94)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "validationFull['Facies']=validation_output\n",
    "make_facies_log_plot(\n",
    "    validationFull[validationFull['Well Name']=='STUART'],\n",
    "    facies_colors=facies_colors)\n",
    "make_facies_log_plot(\n",
    "    validationFull[validationFull['Well Name']=='CRAWFORD'],\n",
    "    facies_colors=facies_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validationFull.to_csv('TangDarnell_sub3.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
