{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import set_option\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Convolution2D, Dense, Input, Dropout, Flatten, MaxPooling2D, Activation\n",
    "from keras.optimizers import Nadam\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "np.random.seed(42)\n",
    "\n",
    "def accuracy(conf):\n",
    "    total_correct = 0.\n",
    "    nb_classes = conf.shape[0]\n",
    "    for i in np.arange(0,nb_classes):\n",
    "        total_correct += conf[i][i]\n",
    "    acc = total_correct/sum(sum(conf))\n",
    "    return acc\n",
    "\n",
    "def label_facies(row, labels):\n",
    "    return labels[ row['Facies'] -1]\n",
    "    \n",
    "\n",
    "set_option(\"display.max_rows\", 10)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "filename = 'facies_vectors.csv'\n",
    "training_data = pd.read_csv(filename)\n",
    "\n",
    "\n",
    "training_data['Well Name'] = training_data['Well Name'].astype('category')\n",
    "training_data['Formation'] = training_data['Formation'].astype('category')\n",
    "training_data['Well Name'].unique()\n",
    "\n",
    "# 1=sandstone  2=c_siltstone   3=f_siltstone \n",
    "# 4=marine_silt_shale 5=mudstone 6=wackestone 7=dolomite\n",
    "# 8=packstone 9=bafflestone\n",
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00',\n",
    "       '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "\n",
    "facies_labels = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS',\n",
    "                 'WS', 'D','PS', 'BS']\n",
    "#facies_color_map is a dictionary that maps facies labels\n",
    "#to their respective colors\n",
    "facies_color_map = {}\n",
    "for ind, label in enumerate(facies_labels):\n",
    "    facies_color_map[label] = facies_colors[ind]\n",
    "\n",
    "training_data.loc[:,'FaciesLabels'] = training_data.apply(lambda row: label_facies(row, facies_labels), axis=1)\n",
    "\n",
    "PE_mask = training_data['PE'].notnull().values\n",
    "\n",
    "mean_pe = training_data['PE'].mean()\n",
    "std_pe = training_data['PE'].std()\n",
    "training_data['PE'] = (training_data['PE']-mean_pe)/std_pe\n",
    "PE_mask = training_data['PE'].notnull().values\n",
    "\n",
    "training_data['PE'] = training_data['PE'].fillna(value=0)\n",
    "\n",
    "correct_facies_labels = training_data['Facies'].values\n",
    "\n",
    "feature_vectors = training_data.drop(['Formation', 'FaciesLabels'], axis=1)#, 'RELPOS', 'NM_M', 'Depth', 'ILD_log10',  'DeltaPHI',   'PHIND'], axis=1)\n",
    "\n",
    "well_labels = training_data[['Well Name', 'Facies']].values\n",
    "data_vectors = feature_vectors.drop(['Well Name', 'Facies'], axis=1).values\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(data_vectors)\n",
    "scaled_features = scaler.transform(data_vectors)\n",
    "\n",
    "data_out = np.hstack([well_labels, scaled_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data_out\n",
    "well_data = {}\n",
    "well_names = list(set(data[:, 0]))\n",
    "for name in well_names:\n",
    "    well_data[name] = [[], []]\n",
    "    \n",
    "for row in data:\n",
    "    well_data[row[0]][1].append(row[1])\n",
    "    well_data[row[0]][0].append(list(row[2::]))\n",
    "\n",
    "positive_lag = 10\n",
    "negative_lag = 11\n",
    "\n",
    "chunks_cnn = []\n",
    "chunk_length = positive_lag+negative_lag+1 #were gonna predict middle facies\n",
    "chunks_facies_cnn = []\n",
    "for name in well_names:\n",
    "    test_well_data = well_data[name]\n",
    "    log_values = np.array(test_well_data[0])\n",
    "    log_values_padded = np.lib.pad(log_values, (negative_lag,positive_lag), 'edge')[:, negative_lag:-positive_lag]\n",
    "    facies_values =  np.array(test_well_data[1])\n",
    "    for i in range(log_values.shape[0]):\n",
    "        chunk = log_values_padded[i:i+chunk_length, :]\n",
    "        chunk_trans = chunk.T\n",
    "        chunks_cnn.append(chunk_trans)\n",
    "        chunks_facies_cnn.append(facies_values[i])\n",
    "\n",
    "chunks_cnn = np.array(chunks_cnn)\n",
    "\n",
    "chunks_facies_cnn = np.array(chunks_facies_cnn, dtype=np.int32)-1\n",
    "unique_facies = len(set(chunks_facies_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = chunks_cnn\n",
    "y = chunks_facies_cnn\n",
    "\n",
    "X = X.reshape((chunks_cnn.shape[0], chunks_cnn.shape[1], chunks_cnn.shape[2], 1))\n",
    "\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "N = 128\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution2D(N, 1, 5, border_mode=\"same\",activation=\"relu\",input_shape=(chunks_cnn.shape[1], chunks_cnn.shape[2], 1)))\n",
    "cnn.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "cnn.add(Dropout(0.25))\n",
    "cnn.add(Convolution2D(N, 1, 3, border_mode=\"same\",activation=\"relu\",input_shape=(chunks_cnn.shape[1], chunks_cnn.shape[2], 1)))\n",
    "cnn.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "#cnn.add(Dropout(0.5))\n",
    "cnn.add(Convolution2D(N, 2, 2, border_mode=\"same\", activation=\"relu\"))\n",
    "#cnn.add(Convolution2D(N, 3, 1, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Dropout(0.8))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(64, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(9, activation=\"softmax\"))\n",
    "cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2779 samples, validate on 1370 samples\n",
      "Epoch 1/50\n",
      "2779/2779 [==============================] - 10s - loss: 2.0862 - acc: 0.1839 - val_loss: 1.9905 - val_acc: 0.3277\n",
      "Epoch 2/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.8598 - acc: 0.3073 - val_loss: 1.6940 - val_acc: 0.3818\n",
      "Epoch 3/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.6397 - acc: 0.3598 - val_loss: 1.4919 - val_acc: 0.3869\n",
      "Epoch 4/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.5338 - acc: 0.3760 - val_loss: 1.3765 - val_acc: 0.4467\n",
      "Epoch 5/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.4568 - acc: 0.4001 - val_loss: 1.2904 - val_acc: 0.4606\n",
      "Epoch 6/50\n",
      "2779/2779 [==============================] - 10s - loss: 1.3965 - acc: 0.4264 - val_loss: 1.2231 - val_acc: 0.5080\n",
      "Epoch 7/50\n",
      "2779/2779 [==============================] - 9s - loss: 1.3470 - acc: 0.4347 - val_loss: 1.2225 - val_acc: 0.5182\n",
      "Epoch 8/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.3025 - acc: 0.4613 - val_loss: 1.2067 - val_acc: 0.5423\n",
      "Epoch 9/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.2870 - acc: 0.4602 - val_loss: 1.1914 - val_acc: 0.5460\n",
      "Epoch 10/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.2703 - acc: 0.4595 - val_loss: 1.1987 - val_acc: 0.5409\n",
      "Epoch 11/50\n",
      "2779/2779 [==============================] - 9s - loss: 1.2493 - acc: 0.4743 - val_loss: 1.1907 - val_acc: 0.5270\n",
      "Epoch 12/50\n",
      "2779/2779 [==============================] - 9s - loss: 1.2264 - acc: 0.5027 - val_loss: 1.1735 - val_acc: 0.5394\n",
      "Epoch 13/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.2395 - acc: 0.4797 - val_loss: 1.1847 - val_acc: 0.5620\n",
      "Epoch 14/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.1988 - acc: 0.4959 - val_loss: 1.1698 - val_acc: 0.5409\n",
      "Epoch 15/50\n",
      "2779/2779 [==============================] - 9s - loss: 1.2085 - acc: 0.5005 - val_loss: 1.1879 - val_acc: 0.5292\n",
      "Epoch 16/50\n",
      "2779/2779 [==============================] - 9s - loss: 1.1749 - acc: 0.5041 - val_loss: 1.1851 - val_acc: 0.5248\n",
      "Epoch 17/50\n",
      "2779/2779 [==============================] - 9s - loss: 1.1682 - acc: 0.5164 - val_loss: 1.1607 - val_acc: 0.5482\n",
      "Epoch 18/50\n",
      "2779/2779 [==============================] - 9s - loss: 1.1634 - acc: 0.5211 - val_loss: 1.1519 - val_acc: 0.5489\n",
      "Epoch 19/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.1530 - acc: 0.5207 - val_loss: 1.1653 - val_acc: 0.5423\n",
      "Epoch 20/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.1369 - acc: 0.5322 - val_loss: 1.1711 - val_acc: 0.5577\n",
      "Epoch 21/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.1228 - acc: 0.5318 - val_loss: 1.1617 - val_acc: 0.5380\n",
      "Epoch 22/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.1228 - acc: 0.5351 - val_loss: 1.1667 - val_acc: 0.5416\n",
      "Epoch 23/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.1277 - acc: 0.5387 - val_loss: 1.1755 - val_acc: 0.5460\n",
      "Epoch 24/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.0816 - acc: 0.5556 - val_loss: 1.1863 - val_acc: 0.5416\n",
      "Epoch 25/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.0806 - acc: 0.5570 - val_loss: 1.1851 - val_acc: 0.5460\n",
      "Epoch 26/50\n",
      "2779/2779 [==============================] - 9s - loss: 1.0892 - acc: 0.5509 - val_loss: 1.1777 - val_acc: 0.5372\n",
      "Epoch 27/50\n",
      "2779/2779 [==============================] - 9s - loss: 1.0827 - acc: 0.5599 - val_loss: 1.1943 - val_acc: 0.5394\n",
      "Epoch 28/50\n",
      "2779/2779 [==============================] - 9s - loss: 1.0873 - acc: 0.5549 - val_loss: 1.1877 - val_acc: 0.5380\n",
      "Epoch 29/50\n",
      "2779/2779 [==============================] - 9s - loss: 1.0424 - acc: 0.5747 - val_loss: 1.1761 - val_acc: 0.5416\n",
      "Epoch 30/50\n",
      "2779/2779 [==============================] - 10s - loss: 1.0361 - acc: 0.5657 - val_loss: 1.2018 - val_acc: 0.5401\n",
      "Epoch 31/50\n",
      "2779/2779 [==============================] - 10s - loss: 1.0616 - acc: 0.5693 - val_loss: 1.1903 - val_acc: 0.5307\n",
      "Epoch 32/50\n",
      "2779/2779 [==============================] - 10s - loss: 1.0450 - acc: 0.5700 - val_loss: 1.1668 - val_acc: 0.5350\n",
      "Epoch 33/50\n",
      "2779/2779 [==============================] - 9s - loss: 1.0353 - acc: 0.5822 - val_loss: 1.1751 - val_acc: 0.5380\n",
      "Epoch 34/50\n",
      "2779/2779 [==============================] - 10s - loss: 1.0344 - acc: 0.5819 - val_loss: 1.1779 - val_acc: 0.5489\n",
      "Epoch 35/50\n",
      "2779/2779 [==============================] - 10s - loss: 1.0206 - acc: 0.5945 - val_loss: 1.2221 - val_acc: 0.5292\n",
      "Epoch 36/50\n",
      "2779/2779 [==============================] - 11s - loss: 1.0380 - acc: 0.5847 - val_loss: 1.2060 - val_acc: 0.5445\n",
      "Epoch 37/50\n",
      "2779/2779 [==============================] - 9s - loss: 1.0377 - acc: 0.5844 - val_loss: 1.1679 - val_acc: 0.5569\n",
      "Epoch 38/50\n",
      "2779/2779 [==============================] - 9s - loss: 1.0206 - acc: 0.5786 - val_loss: 1.1619 - val_acc: 0.5358\n",
      "Epoch 39/50\n",
      "2779/2779 [==============================] - 9s - loss: 0.9936 - acc: 0.5873 - val_loss: 1.1723 - val_acc: 0.5547\n",
      "Epoch 40/50\n",
      "2779/2779 [==============================] - 8s - loss: 1.0039 - acc: 0.5883 - val_loss: 1.1909 - val_acc: 0.5387\n",
      "Epoch 41/50\n",
      "2779/2779 [==============================] - 9s - loss: 0.9778 - acc: 0.6031 - val_loss: 1.1955 - val_acc: 0.5679\n",
      "Epoch 42/50\n",
      "2779/2779 [==============================] - 10s - loss: 1.0025 - acc: 0.5984 - val_loss: 1.1677 - val_acc: 0.5613\n",
      "Epoch 43/50\n",
      "2779/2779 [==============================] - 9s - loss: 0.9960 - acc: 0.6027 - val_loss: 1.1939 - val_acc: 0.5620\n",
      "Epoch 44/50\n",
      "2779/2779 [==============================] - 11s - loss: 0.9905 - acc: 0.6049 - val_loss: 1.1916 - val_acc: 0.5526\n",
      "Epoch 45/50\n",
      "2779/2779 [==============================] - 8s - loss: 0.9661 - acc: 0.6063 - val_loss: 1.1541 - val_acc: 0.5686\n",
      "Epoch 46/50\n",
      "2779/2779 [==============================] - 8s - loss: 0.9946 - acc: 0.5952 - val_loss: 1.1646 - val_acc: 0.5547\n",
      "Epoch 47/50\n",
      "2779/2779 [==============================] - 8s - loss: 0.9661 - acc: 0.6078 - val_loss: 1.1242 - val_acc: 0.5635\n",
      "Epoch 48/50\n",
      "2779/2779 [==============================] - 9s - loss: 0.9729 - acc: 0.6160 - val_loss: 1.1487 - val_acc: 0.5555\n",
      "Epoch 49/50\n",
      "2779/2779 [==============================] - 9s - loss: 0.9758 - acc: 0.6024 - val_loss: 1.1565 - val_acc: 0.5526\n",
      "Epoch 50/50\n",
      "2779/2779 [==============================] - 8s - loss: 0.9543 - acc: 0.6214 - val_loss: 1.1741 - val_acc: 0.5569\n",
      "4149/4149 [==============================] - 4s     \n",
      "\n",
      "[[174  87   7   0   0   0   0   0   0]\n",
      " [ 40 763 131   0   0   5   0   1   0]\n",
      " [  5 244 517   1   0   5   2   6   0]\n",
      " [  0   9   1 155  12  79   4  11   0]\n",
      " [  0   5   6  42  84  81   3  75   0]\n",
      " [  0   0   2  37  35 335   7 165   1]\n",
      " [  0   0   1   3   0   5  76  56   0]\n",
      " [  0   0   9   6   1 119   9 534   8]\n",
      " [  0   0   0   1   0  11   0  37 136]]\n",
      "0.66331869069\n"
     ]
    }
   ],
   "source": [
    "cnn.fit(X, y, nb_epoch=50, validation_split=0.33, batch_size=32, verbose=1, show_accuracy=True, shuffle=True)\n",
    "y_predicted = cnn.predict(X, batch_size=32, verbose=1)\n",
    "\n",
    "y_preds = []\n",
    "for row in y_predicted:\n",
    "    index, value = max(enumerate(row), key=operator.itemgetter(1))\n",
    "    y_preds.append(index)\n",
    "print \"\"    \n",
    "print confusion_matrix(chunks_facies_cnn, y_preds)\n",
    "print f1_score(chunks_facies_cnn, y_preds, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_option(\"display.max_rows\", 10)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "filename = 'validation_data_nofacies_online.csv'\n",
    "test_data = pd.read_csv(filename)\n",
    "\n",
    "\n",
    "test_data['Well Name'] = test_data['Well Name'].astype('category')\n",
    "test_data['Formation'] = test_data['Formation'].astype('category')\n",
    "test_data['Well Name'].unique()\n",
    "\n",
    "## insert reading input data here\n",
    "test_data = test_data\n",
    "\n",
    "PE_mask = test_data['PE'].notnull().values\n",
    "\n",
    "#Subtract mean and stddev from training set\n",
    "test_data['PE'] = (test_data['PE']-mean_pe)/std_pe\n",
    "PE_mask = test_data['PE'].notnull().values\n",
    "\n",
    "test_data['PE'] = test_data['PE'].fillna(value=0)\n",
    "\n",
    "feature_vectors = test_data.drop(['Formation'], axis=1)\n",
    "\n",
    "well_labels_test = test_data[['Well Name']].values\n",
    "data_vectors_test = feature_vectors.drop(['Well Name'], axis=1).values\n",
    "\n",
    "scaled_test_features = scaler.transform(data_vectors_test)\n",
    "\n",
    "data_out_test = np.hstack([well_labels_test, scaled_test_features])\n",
    "\n",
    "\n",
    "#Create our chunks\n",
    "data = data_out_test\n",
    "well_data = {}\n",
    "well_names = list(set(data[:, 0]))\n",
    "for name in well_names:\n",
    "    well_data[name] = [[], []]\n",
    "    \n",
    "for row in data:\n",
    "    well_data[row[0]][1].append(row[1])\n",
    "    well_data[row[0]][0].append(list(row[1::]))\n",
    "\n",
    "positive_lag = 10\n",
    "negative_lag = 11\n",
    "\n",
    "chunks_cnn_test = []\n",
    "chunks_facies_cnn_test = []\n",
    "for name in well_names:\n",
    "    test_well_data = well_data[name]\n",
    "    log_values = np.array(test_well_data[0])\n",
    "    log_values_padded = np.lib.pad(log_values, (negative_lag,positive_lag), 'edge')[:, negative_lag:-positive_lag]\n",
    "    for i in range(log_values.shape[0]):\n",
    "        chunk = log_values_padded[i:i+chunk_length, :]\n",
    "        chunk_trans = chunk.T\n",
    "        chunks_cnn_test.append(chunk_trans)\n",
    "\n",
    "chunks_cnn_test = np.array(chunks_cnn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "830/830 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "X_test = chunks_cnn_test\n",
    "\n",
    "X_test = X_test.reshape((chunks_cnn_test.shape[0], chunks_cnn_test.shape[1], chunks_cnn_test.shape[2], 1))\n",
    "\n",
    "\n",
    "y_predicted = cnn.predict(X_test, batch_size=32, verbose=1)\n",
    "\n",
    "y_preds = []\n",
    "for row in y_predicted:\n",
    "    index, value = max(enumerate(row), key=operator.itemgetter(1))\n",
    "    y_preds.append(index)\n",
    "y_preds = np.array(y_preds)+1   \n",
    "#print confusion_matrix(chunks_facies_cnn_test, y_preds)\n",
    "#print f1_score(chunks_facies_cnn_test, y_preds, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 8 8 8 8 8 8 8 8 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 5 6 5 5 5 5 5 5 5 6 6 6\n",
      " 6 6 6 6 6 6 6 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 2 2 2 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 6 6 6 6 3 3 8 8 8 8 8 6 6 6\n",
      " 6 6 6 8 8 8 8 8 8 8 8 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 8 6 6 8 8 6 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 6 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 8 8 8 8 8 8 8 8 8 6\n",
      " 6 6 6 6 6 6 6 3 3 3 2 2 2 2 2 2 2 2 3 3 8 8 8 8 8 8 8 8 8 8 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8\n",
      " 8 8 8 6 6 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 8 8 8 8 8 8 8 8\n",
      " 6 6 6 6 6 6 5 6 6 6 6 6 6 6 6 6 6 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 6 6 8 8 8 8 8 8 6 6 6 6 6 6 6 3 3 3 3 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 6 6 6 6 6 6 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3\n",
      " 3 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 8 8 8 8 8 8 8 8 8 6 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 3 3 3 8 8 8 8 8 8 8 8 8 8 6 6 6 3 3 3 8 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 6 6 6 8 8 8 6 6 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 6 6 6 6 6 6 6 6 6 6 6 6 6 8 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 5 5 5 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data['Facies'] = pd.Series(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Formation Well Name   Depth      GR  ILD_log10  DeltaPHI  PHIND        PE  \\\n",
      "0     A1 SH    STUART  2808.0  66.276      0.630       3.3  10.65 -0.149544   \n",
      "1     A1 SH    STUART  2808.5  77.252      0.585       6.5  11.95 -0.428514   \n",
      "2     A1 SH    STUART  2809.0  82.899      0.566       9.4  13.60 -0.737613   \n",
      "3     A1 SH    STUART  2809.5  80.671      0.593       9.5  13.25 -0.834695   \n",
      "4     A1 SH    STUART  2810.0  75.971      0.638       8.7  12.35 -0.786712   \n",
      "\n",
      "   NM_M  RELPOS  Facies  \n",
      "0     1   1.000       6  \n",
      "1     1   0.978       8  \n",
      "2     1   0.956       8  \n",
      "3     1   0.933       8  \n",
      "4     1   0.911       8  \n"
     ]
    }
   ],
   "source": [
    "print test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data.to_csv(\"validation_data_with_facies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series(y_preds).to_csv(\"just_facies.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
